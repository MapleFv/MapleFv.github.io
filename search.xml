<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Docker解决logs日志时间不同步问题</title>
    <url>/2022/08/25/Docker%E8%A7%A3%E5%86%B3logs%E6%97%A5%E5%BF%97%E6%97%B6%E9%97%B4%E4%B8%8D%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>🍋 🍋 🍋 🍋 🍋</p>
<span id="more"></span>



<h1 id="Docker解决logs日志时间不同步问题"><a href="#Docker解决logs日志时间不同步问题" class="headerlink" title="Docker解决logs日志时间不同步问题"></a>Docker解决logs日志时间不同步问题</h1><p><strong>第一种方法：启动时进行映射</strong></p>
<p>运行 docker run 添加 -v &#x2F;etc&#x2F;localtime:&#x2F;etc&#x2F;localtime 选项，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8080:80 -v /etc/localtime:/etc/localtime nginx</span><br></pre></td></tr></table></figure>

<p><strong>第二种：复制时区信息到容器</strong></p>
<p>（1）如果本机时区正确直接：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp /etc/localtime nginx:/etc/localtime</span><br></pre></td></tr></table></figure>

<p>可能报错：</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208250505195.png" alt="image-20220825050520111"></p>
<p><strong>解决办法：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp /usr/share/zoneinfo/Asia/Shanghai redis:/etc/localtime</span><br></pre></td></tr></table></figure>

<p>重启容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker restart redis</span><br></pre></td></tr></table></figure>

<p>进入容器进行验证</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it redis bash</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208250507918.png" alt="image-20220825050704814"></p>
<p>（2）如果本机时区不正确：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp /usr/share/zoneinfo/Asia/Shanghai nginx:/etc/localtim</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Docker</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM垃圾回收详解</title>
    <url>/2022/05/22/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<p>👇👇👇👇👇</p>
<span id="more"></span>

<p><a name="In8Wl"></a></p>
<h1 id="minorGC-和-Full-GC区别"><a href="#minorGC-和-Full-GC区别" class="headerlink" title="minorGC 和 Full GC区别"></a>minorGC 和 Full GC区别</h1><p><a name="YG75B"></a></p>
<h1 id="1-揭开-JVM-内存分配与回收的神秘面纱"><a href="#1-揭开-JVM-内存分配与回收的神秘面纱" class="headerlink" title="1 揭开 JVM 内存分配与回收的神秘面纱"></a>1 揭开 JVM 内存分配与回收的神秘面纱</h1><p>Java 堆是垃圾收集器管理的主要区域，因此也被称作<strong>GC 堆（Garbage Collected Heap）。</strong>从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。<strong>进一步划分的目的是更好地回收内存，或者更快地分配内存。</strong><br><a name="KBPke"></a></p>
<h2 id="1-1-对象优先在-eden-区分配"><a href="#1-1-对象优先在-eden-区分配" class="headerlink" title="1.1 对象优先在 eden 区分配"></a>1.1 对象优先在 eden 区分配</h2><p>目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。<br />大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC<br><a name="uAXbe"></a></p>
<h2 id="1-2-大对象直接进入老年代"><a href="#1-2-大对象直接进入老年代" class="headerlink" title="1.2 大对象直接进入老年代"></a>1.2 大对象直接进入老年代</h2><p>为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率<br><a name="zlFaD"></a></p>
<h2 id="1-3-长期存活的对象将进入老年代"><a href="#1-3-长期存活的对象将进入老年代" class="headerlink" title="1.3 长期存活的对象将进入老年代"></a>1.3 长期存活的对象将进入老年代</h2><p><a name="tD6gQ"></a></p>
<h2 id="1-5-主要进行-gc-的区域"><a href="#1-5-主要进行-gc-的区域" class="headerlink" title="1.5 主要进行 gc 的区域"></a>1.5 主要进行 gc 的区域</h2><p>针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种：<br />部分收集 (Partial GC)：</p>
<ul>
<li>新生代收集（<strong>Minor GC</strong> &#x2F; Young GC）：只对新生代进行垃圾收集；</li>
<li>老年代收集（**Major GC **&#x2F; Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；</li>
<li>混合收集（<strong>Mixed GC</strong>）：对整个新生代和部分老年代进行垃圾收集。</li>
</ul>
<p>整堆收集 (Full GC)：收集整个 Java 堆和方法区。等价于MajorGC<br><a name="somKl"></a></p>
<h2 id="1-6-空间分配担保"><a href="#1-6-空间分配担保" class="headerlink" title="1.6 空间分配担保"></a>1.6 空间分配担保</h2><p>空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。<br><a name="lGcp1"></a></p>
<h1 id="2-对象已经死亡？"><a href="#2-对象已经死亡？" class="headerlink" title="2 对象已经死亡？"></a>2 对象已经死亡？</h1><p>堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡（即不能再被任何途径使用的对象）。<br><a name="varSy"></a></p>
<h2 id="2-1-引用计数法"><a href="#2-1-引用计数法" class="headerlink" title="2.1 引用计数法"></a>2.1 引用计数法</h2><p>给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。<br><a name="VCdbZ"></a></p>
<h2 id="2-2-可达性分析算法"><a href="#2-2-可达性分析算法" class="headerlink" title="2.2 可达性分析算法"></a>2.2 可达性分析算法</h2><p>这个算法的基本思想就是通过一系列的称为 <strong>“GC Roots”</strong> 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。<strong>哪些对象可以作为 GC Roots 呢？</strong></p>
<ul>
<li>虚拟机栈(栈帧中的本地变量表)中引用的对象</li>
<li>本地方法栈(Native 方法)中引用的对象</li>
<li>方法区中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>所有被同步锁持有的对象</li>
</ul>
<p><strong>对象可以被回收，就代表一定会被回收吗？</strong><br />经可达性分析后不可达对象暂时处于“缓刑阶段”，要真正宣告一个对象死亡，要经历两个阶段，不可达是第一阶段，然后筛选，筛选的条件是此对象是否有必要执行 finalize 方法。被判定为需要执行的对象被放在一个队列中进行第二次标记，如果依然无法建立引用链，则会被真的回收，JDK9移除了finalize方法。<br><a name="maRPv"></a></p>
<h2 id="2-3-再谈引用"><a href="#2-3-再谈引用" class="headerlink" title="2.3 再谈引用"></a>2.3 再谈引用</h2><p>JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）</p>
<ol>
<li><strong>强引用（StrongReference）</strong></li>
</ol>
<p>使用最普遍的引用。如果一个对象具有强引用，那就类似于<strong>必不可少的生活用品</strong>，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。</p>
<ol start="2">
<li><strong>软引用（SoftReference）</strong></li>
</ol>
<p><strong>可有可无的生活用品。</strong>内存足够，垃圾回收器不会回收塔，如果内存不足就会回收。软引用可用来实现内存敏感的高速缓存。</p>
<ol start="3">
<li><strong>弱引用（WeakReference）</strong></li>
</ol>
<p><strong>可有可无的生活用品。</strong>弱引用与软引用的区别在于：只具有弱引用的对象拥有<strong>更短暂的生命周期</strong>。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，<strong>都会回收它的内存</strong>。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。<br /><strong>4．虚引用（PhantomReference）</strong><br />虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。<br /><strong>虚引用主要用来跟踪对象被垃圾回收的活动</strong>。<br /><strong>虚引用与软引用和弱引用的一个区别在于：</strong> 虚引用必须和引用队列（ReferenceQueue）联合使用。<br />特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为<strong>软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生</strong>。</p>
<p><a name="Rv63N"></a></p>
<h1 id="3-垃圾收集算法"><a href="#3-垃圾收集算法" class="headerlink" title="3 垃圾收集算法"></a>3 垃圾收集算法</h1><p><a name="l2XXD"></a></p>
<h2 id="3-1-标记-清除算法"><a href="#3-1-标记-清除算法" class="headerlink" title="3.1 标记-清除算法"></a>3.1 标记-清除算法</h2><p>先标记不需要被回收的对象，然后清除未标记的对象<br />这种垃圾收集算法会带来两个明显的问题：</p>
<ol>
<li><strong>效率问题</strong></li>
<li><strong>空间问题（标记清除后会产生大量不连续的碎片）</strong><br><a name="UxTof"></a><h2 id="3-2-标记-复制算法"><a href="#3-2-标记-复制算法" class="headerlink" title="3.2 标记-复制算法"></a>3.2 标记-复制算法</h2></li>
</ol>
<p>为了解决效率问题，将内存分类大小相同的两块，每次使用其中的一块，当这一块内存使用完后，就将还存活的对象复制到另一块去，然后把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。<br><a name="Wsauu"></a></p>
<h2 id="3-3-标记-整理算法"><a href="#3-3-标记-整理算法" class="headerlink" title="3.3 标记-整理算法"></a>3.3 标记-整理算法</h2><p>标记之后，让所有存活对象向一端移动，然后直接清理掉端边界以外的内存。<br><a name="og0c3"></a></p>
<h2 id="3-4-分代收集算法"><a href="#3-4-分代收集算法" class="headerlink" title="3.4 分代收集算法"></a>3.4 分代收集算法</h2><p>当前虚拟机的垃圾收集都采用分代收集算法。一般将 java 堆分为新生代和老年代，比如在<strong>新生代</strong>中，每次收集都会有<strong>大量对象死去</strong>，所以可以选择”<strong>标记-复制</strong>“算法，只需要付出<strong>少量对象的复制成本</strong>就可以完成每次垃圾收集。而<strong>老年代</strong>的对象<strong>存活几率是比较高</strong>的，而且没有额外的空间对它进行分配担保，所以我们必须选择<strong>“标记-清除”或“标记-整理”</strong>算法进行垃圾收集。<br><a name="xr1rN"></a></p>
<h1 id="4-垃圾收集器"><a href="#4-垃圾收集器" class="headerlink" title="4 垃圾收集器"></a>4 垃圾收集器</h1><p>垃圾回收算法是方法论，垃圾收集器就是内存回收的具体实现。<br /><strong>我们能做的就是根据具体应用场景选择适合自己的垃圾收集器</strong>。<br><a name="Ex5Oi"></a></p>
<h2 id="4-1-Serial-收集器"><a href="#4-1-Serial-收集器" class="headerlink" title="4.1 Serial 收集器"></a>4.1 Serial 收集器</h2><p>单线程收集器；<br />它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ <strong>“Stop The World”</strong> ），直到它收集结束；<br />新生代采用标记-复制算法，老年代采用标记-整理算法；<br />简单而高效（与其他收集器的单线程相比没有线程交互的开销）；<br />Client模式下的虚拟机首选；<br><a name="L9mOS"></a></p>
<h2 id="4-2-ParNew-收集器"><a href="#4-2-ParNew-收集器" class="headerlink" title="4.2 ParNew 收集器"></a>4.2 ParNew 收集器</h2><p>Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样；<br />新生代采用标记-复制算法，老年代采用标记-整理算法；<br />Server 模式下的虚拟机的首选；<br />除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器）配合工作；<br />补充：</p>
<ul>
<li><strong>并行（Parallel）</strong> ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。</li>
<li><strong>并发（Concurrent）</strong>：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上<br><a name="KeuVO"></a><h2 id="4-3-Parallel-Scavenge-收集器"><a href="#4-3-Parallel-Scavenge-收集器" class="headerlink" title="4.3 Parallel Scavenge 收集器"></a>4.3 Parallel Scavenge 收集器</h2></li>
</ul>
<p>Parallel Scavenge 收集器也是使用标记-复制算法的多线程收集器，它看上去几乎和 ParNew 都一样。<br /> <strong>那么它有什么特别之处呢？</strong><br />Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）<br />CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。<br /><strong>所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。</strong><br />新生代采用标记-复制算法，老年代采用标记-整理算法。<br><a name="WPs2f"></a></p>
<h2 id="4-4-Serial-Old-收集器"><a href="#4-4-Serial-Old-收集器" class="headerlink" title="4.4.Serial Old 收集器"></a>4.4.Serial Old 收集器</h2><p><strong>Serial 收集器的老年代版本</strong><br />它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。<br><a name="GjraW"></a></p>
<h2 id="4-5-Parallel-Old-收集器"><a href="#4-5-Parallel-Old-收集器" class="headerlink" title="4.5 Parallel Old 收集器"></a>4.5 Parallel Old 收集器</h2><p><strong>Parallel Scavenge 收集器的老年代版本</strong>。</p>
<p><a name="K3LhP"></a></p>
<h2 id="4-6-CMS-收集器"><a href="#4-6-CMS-收集器" class="headerlink" title="4.6 CMS 收集器"></a>4.6 CMS 收集器</h2><p>CMS（Concurrent Mark Sweep）以获取最短回收停顿时间为目标的收集器，第一款真正意义上的并发收集器，第一次实现了让垃圾收集线程与用户线基本上程同时工作；适合注重用户体验的情景；<br />从名字中的<strong>Mark Sweep</strong>这两个词可以看出，CMS 收集器是一种 <strong>“标记-清除”</strong>算法实现的；<br />运作更复杂：<strong>初始标记、并发标记、重新标记、并发清除</strong><br />主要优点：<strong>并发收集、低停顿</strong>。<br />缺点：</p>
<ul>
<li><strong>对 CPU 资源敏感；</strong></li>
<li><strong>无法处理浮动垃圾；</strong></li>
<li><strong>它使用的回收算法“标记-清除”算法会导致收集结束时会有大量空间碎片产生。</strong><br><a name="raalH"></a><h2 id="4-7-G1-收集器"><a href="#4-7-G1-收集器" class="headerlink" title="4.7 G1 收集器"></a>4.7 G1 收集器</h2></li>
</ul>
<p>G1 (Garbage-First) 是一款面向服务器的垃圾收集器<br />主要针对配备多个处理器及大容量内存的机器. <br />以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.<br />它具备以下特点：<strong>并行与并发、分代收集</strong>、<strong>空间整合</strong>（全局上是标记整理，局部是标记复制）<strong>可预测的停顿（</strong>建立可预测的停顿时间模型<strong>）</strong><br />G1 收集器的运作大致分为以下几个步骤：<strong>初始标记、并发标记、最终标记、筛选回收</strong><br />G1 收集器在后台维护了一个优先列表，根据Region划分区域，优先选择回收价值最大的区域回收(这也就是它的名字 Garbage-First 的由来) ；这也保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。<br><a name="hxdy7"></a></p>
<h2 id="4-8-ZGC-收集器"><a href="#4-8-ZGC-收集器" class="headerlink" title="4.8 ZGC 收集器"></a>4.8 ZGC 收集器</h2><p>ZGC对标记复制做了重大改进<br />在 ZGC 中出现 Stop The World 的情况会更少！</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title>Java8新特性实战</title>
    <url>/2022/05/24/Java8%E6%96%B0%E7%89%B9%E6%80%A7%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<p>🤳  🤳  🤳  🤳  🤳</p>
<span id="more"></span>

<h1 id="1-interface"><a href="#1-interface" class="headerlink" title="1. interface"></a>1. interface</h1><h2 id="在-Java-8-，接口和抽象类有什么区别的？"><a href="#在-Java-8-，接口和抽象类有什么区别的？" class="headerlink" title="在 Java 8 ，接口和抽象类有什么区别的？"></a>在 Java 8 ，接口和抽象类有什么区别的？</h2><p>接口多继承，类单继承<br>接口的方法是public abstract修饰，变量是public static final修饰。abstract class可以用其他修饰符</p>
<h1 id="2-Lambda表达式"><a href="#2-Lambda表达式" class="headerlink" title="2. Lambda表达式"></a>2. Lambda表达式</h1><h4 id="替代匿名内部类-parameters-gt-statements"><a href="#替代匿名内部类-parameters-gt-statements" class="headerlink" title="替代匿名内部类 (parameters) -&gt;{ statements; }"></a>替代匿名内部类 (parameters) -&gt;{ statements; }</h4><p><strong>集合迭代  forEach</strong></p>
<blockquote>
<p>strings.forEach(System.out::println);<br>上述代码的含义把你遍历出来的每一个对象都用来去调用System.out（也就是PrintStream类的一个实例）的println方法。</p>
</blockquote>
<p><strong>方法的引用 ::</strong></p>
<h4 id="访问变量"><a href="#访问变量" class="headerlink" title="访问变量"></a>访问变量</h4><h1 id="3-Stream"><a href="#3-Stream" class="headerlink" title="3. Stream"></a>3. Stream</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//按照类别分组</span></span><br><span class="line">Map&lt;String, List&lt;Product&gt;&gt; map1 = prodList.stream().collect(Collectors.groupingBy(Product::getCategory));</span><br></pre></td></tr></table></figure>
<p>Stream的特点:</p>
<ol>
<li>通过简单的链式编程，使得它可以方便地对遍历处理后的数据进行再处理。</li>
<li>方法参数都是函数式接口类型；</li>
<li>一个Stream只能操作一次，操作完就关闭了，继续使用这个stream会报错；</li>
<li>stream不保存数据，不改变数据源；</li>
</ol>
<h1 id="4-Optional"><a href="#4-Optional" class="headerlink" title="4. Optional"></a>4. Optional</h1><p>使用Oprional解决NPE(java.lang.NullPointerException)问题，丫就是为NPE而生的，其中可以包含空值或非空值。</p>
<h1 id="5-Date-Time-API"><a href="#5-Date-Time-API" class="headerlink" title="5. Date-Time API"></a>5. Date-Time API</h1><p>这是对java.util.Date强有力的补充，解决了Date类的大部分痛点：</p>
<ol>
<li>非线程安全</li>
<li>时区处理麻烦</li>
<li>各种格式化、和时间计算繁琐</li>
<li>设计有缺陷，Date类同时包含日期和时间；还有一个java.sql.Date，容易混淆</li>
</ol>
]]></content>
      <categories>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux安装Docker，并部署Redis和RabbitMQ</title>
    <url>/2022/08/24/Linux%E5%AE%89%E8%A3%85Docker%EF%BC%8C%E5%B9%B6%E9%83%A8%E7%BD%B2Redis%E5%92%8CRabbitMQ/</url>
    <content><![CDATA[<p>🍋 🍋 🍋 🍋 🍋</p>
<span id="more"></span>



<h1 id="linux-安装docker，并部署Redis及RabbitMQ"><a href="#linux-安装docker，并部署Redis及RabbitMQ" class="headerlink" title="linux 安装docker，并部署Redis及RabbitMQ"></a>linux 安装docker，并部署Redis及RabbitMQ</h1><blockquote>
<p><strong>安装环境：CentOS7.x</strong></p>
</blockquote>
<h2 id="1-安装docker"><a href="#1-安装docker" class="headerlink" title="1 安装docker"></a>1 安装docker</h2><p>（1）yum包更新到最新</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum update</span><br></pre></td></tr></table></figure>

<p>（2）安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</span><br></pre></td></tr></table></figure>

<p>（3）设置yum源为阿里云</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<p>（4）安装docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce</span><br></pre></td></tr></table></figure>

<p>（5）安装后查看docker版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker -v</span><br></pre></td></tr></table></figure>



<h2 id="2-设置ustc的镜像"><a href="#2-设置ustc的镜像" class="headerlink" title="2 设置ustc的镜像"></a>2 设置ustc的镜像</h2><p>ustc是老牌的linux镜像服务提供者了，还在遥远的ubuntu 5.04版本的时候就在用。ustc的docker镜像加速器速度很快。ustc docker mirror的优势之一就是不需要注册，是真正的公共服务。</p>
<p>编辑该文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vi /etc/docker/daemon.json  </span><br></pre></td></tr></table></figure>

<p>在该文件中输入如下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-Docker的启动与停止"><a href="#3-Docker的启动与停止" class="headerlink" title="3 Docker的启动与停止"></a>3 Docker的启动与停止</h2><p>systemctl命令是系统服务管理器指令<br>启动docker：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<p>查看docker状态：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl status docker</span><br></pre></td></tr></table></figure>

<p>停止docker：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure>

<p>重启docker：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<p>开机启动：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure>

<p>查看docker概要信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure>

<p>查看docker帮助文档</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker --help</span><br></pre></td></tr></table></figure>



<h2 id="4-常用命令"><a href="#4-常用命令" class="headerlink" title="4 常用命令"></a>4 常用命令</h2><h3 id="4-1-镜像相关"><a href="#4-1-镜像相关" class="headerlink" title="4.1 镜像相关"></a>4.1 镜像相关</h3><p><strong>查看镜像</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure>

<p>REPOSITORY：镜像名称</p>
<p>TAG：镜像标签</p>
<p>IMAGE ID：镜像ID</p>
<p>CREATED：镜像的创建日期（不是获取该镜像的日期）</p>
<p>SIZE：镜像大小</p>
<p>这些镜像都是存储在Docker宿主机的&#x2F;var&#x2F;lib&#x2F;docker目录下</p>
<p><strong>搜索镜像</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker search 镜像名称</span><br></pre></td></tr></table></figure>

<p>NAME：仓库名称<br>DESCRIPTION：镜像描述<br>STARS：用户评价，反应一个镜像的受欢迎程度<br>OFFICIAL：是否官方<br>AUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的</p>
<p><strong>拉取镜像</strong></p>
<p>拉取镜像就是从中央仓库中下载镜像到本地</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull 镜像名称</span><br></pre></td></tr></table></figure>

<p>例如，我要下载centos7镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull centos:7</span><br></pre></td></tr></table></figure>

<p><strong>删除镜像</strong></p>
<p>按镜像ID删除镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rmi 镜像ID</span><br></pre></td></tr></table></figure>

<p>删除所有镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rmi `docker images -q`</span><br></pre></td></tr></table></figure>

<h3 id="4-2-容器相关"><a href="#4-2-容器相关" class="headerlink" title="4.2 容器相关"></a>4.2 容器相关</h3><h4 id="4-2-1-查看容器"><a href="#4-2-1-查看容器" class="headerlink" title="4.2.1 查看容器"></a>4.2.1 查看容器</h4><p>查看正在运行的容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure>

<p>查看所有容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps –a</span><br></pre></td></tr></table></figure>

<p>查看最后一次运行的容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps –l</span><br></pre></td></tr></table></figure>

<p>查看停止的容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps -f status=exited</span><br></pre></td></tr></table></figure>

<h4 id="4-2-2-创建与启动容器"><a href="#4-2-2-创建与启动容器" class="headerlink" title="4.2.2 创建与启动容器"></a>4.2.2 创建与启动容器</h4><p>创建容器常用参数说明：</p>
<p>（1）创建容器命令：docker run</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-i：表示运行容器</span><br><span class="line">-t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。</span><br><span class="line">--name :为创建的容器命名。</span><br><span class="line">-v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文</span><br><span class="line">件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。</span><br><span class="line">-d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t</span><br><span class="line">两个参数，创建后就会自动进去容器）。</span><br><span class="line">-p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射</span><br></pre></td></tr></table></figure>



<p>（2）退出当前容器：exit</p>
<p>（3）守护式方式创建容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -di --name=容器名称 镜像名称:标签</span><br></pre></td></tr></table></figure>

<p>登录守护式容器方式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it 容器名称 (或者容器ID)  /bin/bash</span><br></pre></td></tr></table></figure>

<h4 id="4-2-3-停止与启动容器"><a href="#4-2-3-停止与启动容器" class="headerlink" title="4.2.3 停止与启动容器"></a>4.2.3 停止与启动容器</h4><p>停止容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker stop 容器名称（或者容器ID）</span><br></pre></td></tr></table></figure>

<p>启动容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker start 容器名称（或者容器ID）</span><br></pre></td></tr></table></figure>

<h4 id="4-2-4-文件拷贝"><a href="#4-2-4-文件拷贝" class="headerlink" title="4.2.4 文件拷贝"></a>4.2.4 文件拷贝</h4><p>如果我们需要将文件拷贝到容器内可以使用cp命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp 需要拷贝的文件或目录 容器名称:容器目录 </span><br></pre></td></tr></table></figure>

<p>也可以将文件从容器内拷贝出来</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp 容器名称:容器目录 需要拷贝的文件或目录 </span><br></pre></td></tr></table></figure>

<h4 id="4-2-5-目录挂载"><a href="#4-2-5-目录挂载" class="headerlink" title="4.2.5 目录挂载"></a>4.2.5 目录挂载</h4><p>我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。 创建容器 添加-v参数 后边为 宿主机目录:容器目录，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -di -v /usr/local/myhtml:/usr/local/myhtml --name=mycentos3 centos:7</span><br></pre></td></tr></table></figure>

<p>如果你共享的是多级的目录，可能会出现权限不足的提示。<br>这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数 –privileged&#x3D;true 来解决挂载的目录没<br>有权限的问题</p>
<h4 id="4-2-6-查看容器IP地址"><a href="#4-2-6-查看容器IP地址" class="headerlink" title="4.2.6 查看容器IP地址"></a>4.2.6 查看容器IP地址</h4><p>我们可以通过以下命令查看容器运行的各种数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker inspect 容器名称（容器ID） </span><br></pre></td></tr></table></figure>

<p>也可以直接执行下面的命令直接输出IP地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker inspect --format=&#x27;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#x27; 容器名称（容器ID）</span><br></pre></td></tr></table></figure>

<h4 id="4-2-7-删除容器"><a href="#4-2-7-删除容器" class="headerlink" title="4.2.7 删除容器"></a>4.2.7 删除容器</h4><p>删除指定容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rm 容器名称（容器ID）</span><br></pre></td></tr></table></figure>



<h2 id="5-Dockerfile"><a href="#5-Dockerfile" class="headerlink" title="5 Dockerfile"></a>5 Dockerfile</h2><h3 id="5-1-什么是Dockerfile"><a href="#5-1-什么是Dockerfile" class="headerlink" title="5.1 什么是Dockerfile"></a>5.1 什么是Dockerfile</h3><p>Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。</p>
<p>1、对于开发人员：可以为开发团队提供一个完全一致的开发环境； 2、对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了； 3、对于运维人员：在部署时，可以实现应用的无缝移植。</p>
<h3 id="5-2-常用命令"><a href="#5-2-常用命令" class="headerlink" title="5.2 常用命令"></a>5.2 常用命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>FROM image_name:tag</td>
<td>定义了使用哪个基础镜像启动构建流程</td>
</tr>
<tr>
<td>MAINTAINER user_name</td>
<td>声明镜像的创建者</td>
</tr>
<tr>
<td>ENV key value</td>
<td>设置环境变量 (可以写多条)</td>
</tr>
<tr>
<td>RUN command</td>
<td>是Dockerfile的核心部分(可以写多条)</td>
</tr>
<tr>
<td>ADD source_dir&#x2F;file<br/>dest_dir&#x2F;file</td>
<td>将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压</td>
</tr>
<tr>
<td>COPY source_dir&#x2F;file<br/>dest_dir&#x2F;file</td>
<td>和ADD相似，但是如果有压缩文件并不能解压</td>
</tr>
<tr>
<td>WORKDIR path_dir</td>
<td>设置工作目录</td>
</tr>
</tbody></table>
<h3 id="5-3-使用脚本创建镜像"><a href="#5-3-使用脚本创建镜像" class="headerlink" title="5.3 使用脚本创建镜像"></a>5.3 使用脚本创建镜像</h3><p>步骤：<br>（1）创建目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir –p /usr/local/dockerjdk8 </span><br></pre></td></tr></table></figure>

<p>（2）下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的&#x2F;usr&#x2F;local&#x2F;dockerjdk8目录<br>（3）创建文件Dockerfile </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vi Dockerfile</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">依赖镜像名称和ID</span> </span><br><span class="line"></span><br><span class="line">FROM centos:7 </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">指定镜像创建者信息</span> </span><br><span class="line"></span><br><span class="line">MAINTAINER ITCAST </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">切换工作目录</span> </span><br><span class="line"></span><br><span class="line">WORKDIR /usr </span><br><span class="line"></span><br><span class="line">RUN mkdir  /usr/local/java </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ADD 是相对路径jar,把java添加到容器中</span> </span><br><span class="line"></span><br><span class="line">ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置java环境变量</span> </span><br><span class="line">ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 </span><br><span class="line">ENV JRE_HOME $JAVA_HOME/jre </span><br><span class="line">ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH </span><br><span class="line">ENV PATH $JAVA_HOME/bin:$PATH </span><br></pre></td></tr></table></figure>

<p>（4）执行命令构建镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker build -t=&#x27;jdk1.8&#x27; . </span><br></pre></td></tr></table></figure>

<p>注意后边的空格和点，不要省略</p>
<p>（5）查看镜像是否建立完成</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker images </span><br></pre></td></tr></table></figure>



<h2 id="6-Docker创建Redis容器"><a href="#6-Docker创建Redis容器" class="headerlink" title="6 Docker创建Redis容器"></a>6 Docker创建Redis容器</h2><h3 id="6-1-在宿主机-x2F-usr-x2F-local目录下，创建一个docker-redis目录"><a href="#6-1-在宿主机-x2F-usr-x2F-local目录下，创建一个docker-redis目录" class="headerlink" title="6.1 在宿主机&#x2F;usr&#x2F;local目录下，创建一个docker_redis目录"></a>6.1 在宿主机&#x2F;usr&#x2F;local目录下，创建一个docker_redis目录</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@bogon local]# mkdir docker_redis</span><br></pre></td></tr></table></figure>

<h3 id="6-2-在redis官网下载最新版本http-www-redis-cn-download-html，主要拿到包里的配置文件redis-conf"><a href="#6-2-在redis官网下载最新版本http-www-redis-cn-download-html，主要拿到包里的配置文件redis-conf" class="headerlink" title="6.2 在redis官网下载最新版本http://www.redis.cn/download.html，主要拿到包里的配置文件redis.conf"></a>6.2 在redis官网下载最新版本<a href="http://www.redis.cn/download.html%EF%BC%8C%E4%B8%BB%E8%A6%81%E6%8B%BF%E5%88%B0%E5%8C%85%E9%87%8C%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6redis.conf">http://www.redis.cn/download.html，主要拿到包里的配置文件redis.conf</a></h3><p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208240251961.png" alt="image-20220824025148759"></p>
<h3 id="6-3-修改redis-conf配置文件"><a href="#6-3-修改redis-conf配置文件" class="headerlink" title="6.3 修改redis.conf配置文件"></a>6.3 修改redis.conf配置文件</h3><p><strong>（1）bind 127.0.0.1 #注释掉这部分，使redis可以外部访问</strong></p>
<p><strong>（2）daemonize no#用守护线程的方式启动</strong></p>
<p><strong>&#x3D;&#x3D;（3）requirepass 你的密码#给redis设置密码&#x3D;&#x3D;</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">requirepass 123456</span><br></pre></td></tr></table></figure>

<p><strong>（4）appendonly yes  #redis持久化　　默认是no</strong></p>
<h3 id="6-4-将redis-conf放在-x2F-usr-x2F-local-x2F-docker-redis-x2F-文件下"><a href="#6-4-将redis-conf放在-x2F-usr-x2F-local-x2F-docker-redis-x2F-文件下" class="headerlink" title="6.4 将redis.conf放在&#x2F;usr&#x2F;local&#x2F;docker_redis&#x2F;文件下"></a>6.4 将redis.conf放在&#x2F;usr&#x2F;local&#x2F;docker_redis&#x2F;文件下</h3><h3 id="6-5-启动redis容器"><a href="#6-5-启动redis容器" class="headerlink" title="6.5 启动redis容器"></a>6.5 启动redis容器</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@bogon docker_redis]# docker run --restart=always -p 6379:6379 --name redis \</span><br><span class="line">&gt; -v /usr/local/docker_redis/redis.conf:/etc/redis/redis.conf \</span><br><span class="line">&gt; -v /usr/local/docker_redis/data:/data \</span><br><span class="line">&gt; -v /etc/localtime:/etc/localtime \</span><br><span class="line">&gt; -d redis:6.0.6 redis-server /etc/redis/redis.conf --appendonly yes</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>&#x3D;&#x3D;<strong>这里注意，redis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf  是以容器内文件运行redis,而不是宿主机文件</strong>&#x3D;&#x3D;</p>
<p>参考：<a href="https://copyfuture.com/blogs-details/202204150247524873">https://copyfuture.com/blogs-details/202204150247524873</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208240252703.png" alt="image-20220824025240585"></p>
<table>
<thead>
<tr>
<th align="left">命令</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">–name redis</td>
<td align="left">启动容器的名字</td>
</tr>
<tr>
<td align="left">-d</td>
<td align="left">后台运行</td>
</tr>
<tr>
<td align="left">-p 6379:6379</td>
<td align="left">将容器的 6379(后面那个) 端口映射到主机的 6379(前面那个) 端口</td>
</tr>
<tr>
<td align="left">–restart unless-stopped</td>
<td align="left">容器重启策略</td>
</tr>
<tr>
<td align="left">-v &#x2F;home&#x2F;redis&#x2F;data:&#x2F;data</td>
<td align="left">将Redis储存文件夹挂在到主机</td>
</tr>
<tr>
<td align="left">-v &#x2F;home&#x2F;redis&#x2F;conf&#x2F;redis.conf:&#x2F;etc&#x2F;redis&#x2F;redis.conf</td>
<td align="left">将配置文件夹挂在到主机</td>
</tr>
<tr>
<td align="left">-v &#x2F;etc&#x2F;localtime:&#x2F;etc&#x2F;localtime</td>
<td align="left">本地时间同步容器时间  方便以后日志时间同步本地时间</td>
</tr>
<tr>
<td align="left">-d redis:bullseye</td>
<td align="left">启动哪个版本的 Redis (本地镜像的版本)</td>
</tr>
<tr>
<td align="left">redis-server &#x2F;etc&#x2F;redis&#x2F;redis.conf</td>
<td align="left">Redis 容器中设置 redis-server 每次启动读取 &#x2F;etc&#x2F;redis&#x2F;redis.conf 这个配置为准</td>
</tr>
<tr>
<td align="left">–appendonly yes</td>
<td align="left">在Redis容器启动redis-server服务器并打开Redis持久化配置</td>
</tr>
<tr>
<td align="left">\</td>
<td align="left">shell 命令换行</td>
</tr>
</tbody></table>
<p> 注意 : 命令中所有 冒号 前面的是主机配置 , 冒号 后面的是redis容器配置 。<br>–restart unless-stopped : 在docker重启时重启当前容器。但不包含docker重启时已停止的容器。</p>
<p>安装完后的一些可选择性操作：</p>
<p>查看最近30分钟reids容器日志</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker logs --since=30m redis</span><br></pre></td></tr></table></figure>

<p>尝试进入redis服务器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it myredis redis-cli</span><br></pre></td></tr></table></figure>

<p>在服务器里验证密码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">auth 123456</span><br></pre></td></tr></table></figure>



<h3 id="6-6-如果创建时未指定-–restart-x3D-always-可通过update-命令设置"><a href="#6-6-如果创建时未指定-–restart-x3D-always-可通过update-命令设置" class="headerlink" title="6.6 如果创建时未指定 –restart&#x3D;always ,可通过update 命令设置"></a>6.6 如果创建时未指定 –restart&#x3D;always ,可通过update 命令设置</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">docker update --restart=always 容器名称</span><br></pre></td></tr></table></figure>



<h3 id="6-7-尝试使用RedisDesktopManager远程链接redis容器"><a href="#6-7-尝试使用RedisDesktopManager远程链接redis容器" class="headerlink" title="6.7 尝试使用RedisDesktopManager远程链接redis容器"></a>6.7 尝试使用RedisDesktopManager远程链接redis容器</h3><p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208240253138.png" alt="image-20220824025330003"></p>
<p>在命令行验证密码</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208240253718.png" alt="image-20220824025307596"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-----------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">--------------------------------------20228.25更新---------------------------------------</span><br><span class="line"></span><br><span class="line">隐藏bug：使用RedisDesktopManager一直无法远程redis，报错：访问拒绝，或者是</span><br><span class="line"></span><br><span class="line">Connection: Connection error: The proxy type is invalid for this operation</span><br><span class="line"></span><br><span class="line">降低版本</span><br><span class="line"></span><br><span class="line">由0.9降到了0.8.8</span><br></pre></td></tr></table></figure>





<h2 id="7-Docker中的RabbitMQ安装"><a href="#7-Docker中的RabbitMQ安装" class="headerlink" title="7 Docker中的RabbitMQ安装"></a>7 Docker中的RabbitMQ安装</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方式一：默认guest 用户，密码也是 guest</span></span><br><span class="line">docker run -d --hostname my-rabbit --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq:management</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方式二：设置用户名root，密码123456</span></span><br><span class="line">docker run -d --hostname my-rabbit --name rabbit -e RABBITMQ_DEFAULT_USER=root -e RABBITMQ_DEFAULT_PASS=123456 -p 15672:15672 -p 5672:5672 rabbitmq:management</span><br></pre></td></tr></table></figure>



<h3 id="7-1-在官网选择合适镜像"><a href="#7-1-在官网选择合适镜像" class="headerlink" title="7.1 在官网选择合适镜像"></a>7.1 在官网选择合适镜像</h3><p><a href="https://hub.docker.com/_/rabbitmq/tags">https://hub.docker.com/_/rabbitmq/tags</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208240251838.png" alt="image-20220824025107677"></p>
<h3 id="7-2-拉取最新镜像"><a href="#7-2-拉取最新镜像" class="headerlink" title="7.2 拉取最新镜像"></a>7.2 拉取最新镜像</h3><p>注意：如果 <code>docker pull rabbitmq</code> 后面不带<code>management</code>，启动 RabbitMQ 后是无法打开管理界面的，所以我们要下载带 management 插件的 RabbitMQ。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull rabbitmq:latest</span><br></pre></td></tr></table></figure>

<h3 id="7-3-创建一个文件夹，用于挂载rabbitmq容器数据"><a href="#7-3-创建一个文件夹，用于挂载rabbitmq容器数据" class="headerlink" title="7.3 创建一个文件夹，用于挂载rabbitmq容器数据"></a>7.3 创建一个文件夹，用于挂载rabbitmq容器数据</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /usr/local/docker_rabbitmq</span><br></pre></td></tr></table></figure>



<h3 id="7-4-启动容器"><a href="#7-4-启动容器" class="headerlink" title="7.4 启动容器"></a>7.4 启动容器</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name rabbit --hostname myRabbit -p 5672:5672 -p 15672:15672 -v /usr/local/docker_rabbitmq:/var/lib/rabbitmq  rabbitmq</span><br></pre></td></tr></table></figure>

<p>第一个-p ：用于页面访问使用<br>第二个-p ：用于生产和消费端使用（也就是再代码里使用）</p>
<h3 id="7-5-进入容器，执行下面命令"><a href="#7-5-进入容器，执行下面命令" class="headerlink" title="7.5 进入容器，执行下面命令"></a>7.5 进入容器，执行下面命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it b19950aae8d0 /bin/bash</span><br><span class="line"></span><br><span class="line">rabbitmq-plugins enable rabbitmq_management</span><br></pre></td></tr></table></figure>

<h3 id="7-6-退出容器，访问一下rabbitmq-web界面，登录用户名和密码默认都是guest，安装完成"><a href="#7-6-退出容器，访问一下rabbitmq-web界面，登录用户名和密码默认都是guest，安装完成" class="headerlink" title="7.6 退出容器，访问一下rabbitmq web界面，登录用户名和密码默认都是guest，安装完成"></a>7.6 退出容器，访问一下rabbitmq web界面，登录用户名和密码默认都是guest，安装完成</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://宿主机IP:15672</span><br></pre></td></tr></table></figure>

<p><strong>&#x3D;&#x3D;通过本地去访问镜像记得关闭虚拟机的防火墙&#x3D;&#x3D;</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202208240254885.png" alt="image-20220824025425765"></p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Docker</tag>
        <tag>Redis</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Quick Start</title>
    <url>/2022/05/07/Quick%20Start/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Win10下Hexo博客搭建教程，及阿里云服务器部署实战</title>
    <url>/2022/05/07/Win10%E4%B8%8BHexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B%EF%BC%8C%E5%8F%8A%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<p>🍈🍈🍈🍈🍈</p>
<span id="more"></span>



<h2 id="1-在本地计算机安装Hexo环境"><a href="#1-在本地计算机安装Hexo环境" class="headerlink" title="1. 在本地计算机安装Hexo环境"></a>1. 在本地计算机安装Hexo环境</h2><h2 id="2-服务端准备工作"><a href="#2-服务端准备工作" class="headerlink" title="2. 服务端准备工作"></a>2. 服务端准备工作</h2><h2 id="3-Hexo博客的阿里云部署"><a href="#3-Hexo博客的阿里云部署" class="headerlink" title="3. Hexo博客的阿里云部署"></a>3. Hexo博客的阿里云部署</h2><h2 id="4-其它配置"><a href="#4-其它配置" class="headerlink" title="4. 其它配置"></a>4. 其它配置</h2>]]></content>
      <tags>
        <tag>blogs</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务</title>
    <url>/2022/05/24/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<p>🍋 🍋 🍋 🍋 🍋</p>
<span id="more"></span>

<h1 id="1-事务"><a href="#1-事务" class="headerlink" title="1 事务"></a>1 事务</h1><p>事务是逻辑上的一组操作，要么都执行，要么都不执行。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101646.png" alt="img"></p>
<h1 id="2-数据库事务"><a href="#2-数据库事务" class="headerlink" title="2 数据库事务"></a>2 数据库事务</h1><p>大多数情况下，我们在谈论事务的时候，如果没有特指分布式事务，往往指的就是数据库事务。</p>
<h2 id="2-1-数据库事务有什么作用？"><a href="#2-1-数据库事务有什么作用？" class="headerlink" title="2.1 数据库事务有什么作用？"></a>2.1 数据库事务有什么作用？</h2><p>简单来说，数据库事务可以保证多个对数据库的操作（也就是SQL语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：<strong>要么全部执行成功，要么全部不执行</strong><br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101761.png" alt="img"></p>
<p>另外，关系型数据库（MySql、SQL Server、Oracle等）事务都有ACID特性：</p>
<ol>
<li><strong>原子性（Atomicity）</strong>：事务是最小的执行单位，不允许分割，事务的原子性确保动作要么全部完成，要么完全不起作用；</li>
<li><strong>一致性（Consistency）</strong>：执行事务后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款者的总额应该是不变的；</li>
<li><strong>隔离性（Isolation）</strong>：并发访问数据库时，一个用户的事务不被其他事物所干扰，并发事务之间数据库是独立的；</li>
<li>**持久性(Durability)**：一个事务被提交之后，他对数据库中数据的改变是持久的，即数据库发生故障也不应该对其有任何影响、。</li>
</ol>
<p>这里补充一下，只有保证了事务的<strong>原子性、隔离性、持久性</strong>之后，<strong>一致性</strong>才能得到保障。也就是说AID是手段，C是目的。</p>
<h2 id="2-2-数据库事务的实现原理"><a href="#2-2-数据库事务的实现原理" class="headerlink" title="2.2 数据库事务的实现原理"></a>2.2 数据库事务的实现原理</h2><p>我们这里以MySQL的InnoDB引擎为例来简单说一下。<br>MySQL InnoDB引擎使用<strong>redo log(重做日志)<strong>保证事务的持久性，使用</strong>undo log(回滚日志)<strong>来保证事务的原子性。MySQL InnoDB引擎通过</strong>锁机制、MVCC</strong>等手段来保证事物的隔离性（默认支持的隔离级别是REPEATABLE-READ）;</p>
<h1 id="3-分布式事务"><a href="#3-分布式事务" class="headerlink" title="3 分布式事务"></a>3 分布式事务</h1><blockquote>
<p>微服务架构下，一个系统被拆分为多个小的微服务。每个微服务都可能存在不同的机器上，并且每个微服务可能都有一个单独的数据库供自己使用。这种情况下，一组操作可能会涉及到多个微服务以及多个数据库。举个例子:电商系统中，你创建一个订单往往会涉及到订单服务〈订单数加一)、库存服务（库存减一）等等服务，这些服务会有供自己单独使用的数据库。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101417.png" alt="img"></p>
<blockquote>
<p>这个时候单单依靠数据库事务就不行了!我们就需要引入<strong>分布式事务</strong>这个概念了!<br>实际上，只要跨数据库的场景都需要用到引入分布式事务。比如说单个数据库的性能达到瓶颈或者数据量太大的时候，我们需要进行<strong>分库</strong>。分库之后，同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101735.png" alt="img"></p>
<blockquote>
<p>一言蔽之，<strong>分布式事务的终极目标就是保证系统中多个相关联的数据库中的数据的一致性!</strong><br>那既然分布式事务也属于事务，理论上就应该准守事物的ACID四大特性。但是，考虑到性能、可用性等各方面因素，我们往往是无法完全满足ACID的，只能选择一个比较折中的方案。<br>针对分布式事务，又诞生了一些新的理论。</p>
</blockquote>
<h1 id="4-分布式事务基础理论"><a href="#4-分布式事务基础理论" class="headerlink" title="4 分布式事务基础理论"></a>4 分布式事务基础理论</h1><h2 id="4-1-CAP理论和BASE理论"><a href="#4-1-CAP理论和BASE理论" class="headerlink" title="4.1 CAP理论和BASE理论"></a>4.1 CAP理论和BASE理论</h2><p>看这篇文章<a href="https://www.yuque.com/maple-chdh2/ctkseg/dgwype"><strong>理论&amp;算法&amp;协议</strong></a></p>
<h2 id="4-2-一致性的三种级别"><a href="#4-2-一致性的三种级别" class="headerlink" title="4.2 一致性的三种级别"></a>4.2 一致性的三种级别</h2><p>对一致性（Consistency）可以分为三种级别：<br>1．强一致性︰系统写入了什么，读出来的就是什么。<br>2．弱一致性︰不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保<br>证某个时刻达到数据一致的状态。<br>3．最终一致性:弱一致性的升级版。系统会保证在一定时间内达到数据一致的状态，</p>
<h2 id="4-3-柔性事务"><a href="#4-3-柔性事务" class="headerlink" title="4.3 柔性事务"></a>4.3 柔性事务</h2><p>互联网应用最关键的就是要保证高可用，计算式系统几秒钟之内没办法使用都有可能造成数百万的损失。在此场景下，一些大佬们在CAP理论和BASE理论的基础上，提出了<strong>柔性事务</strong>的概念。<strong>柔性事务追求的是最终一致性</strong>。<br>实际上，柔性事务就是<strong>BASE理论＋业务实践</strong>。柔性事务追求的目标是:我们根据自身业务特性，通过适当的方式来保证系统数据的最终一致性。像<strong>TCC、 Saga、MQ事务、本地消息表</strong>就属于柔性事务。</p>
<h2 id="4-4-刚性事务"><a href="#4-4-刚性事务" class="headerlink" title="4.4 刚性事务"></a>4.4 刚性事务</h2><p>与柔性事务相对的就是<strong>刚性事务</strong>了。前面我们说了，<strong>柔性事务追求的是最终一致性</strong>。那么，与之对应，刚性事务追求的就是<strong>强一致性</strong>。像<strong>2PC、3PC</strong>就属于刚性事务。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101849.png" alt="img"></p>
<h1 id="5-分布式事务解决方案"><a href="#5-分布式事务解决方案" class="headerlink" title="5 分布式事务解决方案"></a>5 分布式事务解决方案</h1><h2 id="5-1-2PC（两阶段提交协议）"><a href="#5-1-2PC（两阶段提交协议）" class="headerlink" title="5.1 2PC（两阶段提交协议）"></a>5.1 2PC（两阶段提交协议）</h2><h3 id="5-1-1-准备阶段（Prepare）"><a href="#5-1-1-准备阶段（Prepare）" class="headerlink" title="5.1.1 准备阶段（Prepare）"></a>5.1.1 准备阶段（Prepare）</h3><p>准备阶段的核心是“询问”事务参与者执行本地数据库事务操作是否成功。<br>1．<strong>事务协调者&#x2F;管理者</strong>向所有参与者发送消息询问:“你是否可以执行事务操作呢?”，并等待其答复。<br>2．<strong>事务参</strong>与者接收到消息之后，开始执行本地数据库事务预操作比如写redo log&#x2F;undo log日志。但是，此时<br>并不会提交事务!<br>3．<strong>事务参与者</strong>如果执行本地数据库事务操作成功，那就回复:“就绪”，否则就回复:“未就绪”。</p>
<h3 id="5-1-2-提交阶段（Commit）"><a href="#5-1-2-提交阶段（Commit）" class="headerlink" title="5.1.2 提交阶段（Commit）"></a>5.1.2 提交阶段（Commit）</h3><p>提交阶段的核心是“询问”事务参与者提交事务是否成功。<br>当所有事务参与者都是“就绪”状态的话:<br>1．<strong>事务协调者&#x2F;管理者</strong>向所有参与者发送消息:“你们可以提交事务啦! ”(<strong>commit消息</strong>)<br>2．<strong>事务参与者</strong>接收到<strong>commit消息</strong>后执行<strong>提交本地数据库事务</strong>操作，执行完成之后释<strong>放整个事务期间所占用</strong><br><strong>的资源</strong>。<br>3．<strong>事务参与者</strong>回复:“事务已经提交”(ack 消息)。<br>4．事<strong>务协调者&#x2F;管理者</strong>收到所有<strong>事务参与者</strong>的<strong>ack消息</strong>之后，整个分布式事务过程正式结束。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101541.png" alt="img"></p>
<p>当任一事务参与者是“未就绪”状态的话:<br>1．<strong>事务协调者&#x2F;管理者</strong>向所有参与者发送消息:“你们可以执行回滚操作了! ”(<strong>rollback消息</strong>)。<br>2．<strong>事务参与者</strong>接收到** rollback消息<strong>后执行</strong>本地数据库事务回滚<strong>执行完成之后</strong>释放整个事务期间所占用的资**<br><strong>源</strong>。<br>3．<strong>事务参与者</strong>回复:“事务已经回滚”(<strong>ack 消息</strong>)。<br>4．<strong>事务协调者&#x2F;管理者</strong>收到所有<strong>事务参与者</strong>的<strong>ack消息</strong>之后，取消事务。</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251101103.png" alt="img"></p>
<h3 id="5-1-3-总结"><a href="#5-1-3-总结" class="headerlink" title="5.1.3 总结"></a>5.1.3 总结</h3><p>简单总结一下2PC两阶段中比较重要的一些点:<br>1．<strong>准备阶段</strong>的主要目的是测试<strong>事务参与者</strong>能否执行<strong>本地数据库事务</strong>操作(!!注意:这一步并不会提交事<br>务)。<br>2．<strong>提交阶段</strong>中<strong>事务协调者&#x2F;管理者</strong>会根据<strong>准备阶段</strong>中<strong>事务参与者</strong>的消息来决定是执行事务提交还是回滚操<br>作。<br>3．<strong>提交阶段</strong>之后—定会结束当前的分布式事务<br><strong>2PC的优点:</strong></p>
<ol>
<li>实现起来非常简单，各大主流数据库比如MySQL、Oracle都有自己实现。</li>
<li>针对的是数据强一致性。不过，仍然可能存在数据不一致的情况。</li>
</ol>
<p><strong>2PC存在的问题:</strong></p>
<ol>
<li><strong>同步阻塞</strong>：事务参与者会在正式提交事务之前会一直占用相关的资源。比如用户小明转账给小红，那其他事务也要操作用户小明或小红的话，就会阻塞。</li>
<li><strong>数据不一致</strong>：由于网络问题或者事务协调者&#x2F;管理者宕机都有可能会造成数据不一致的情况。比如在第2阶段</li>
</ol>
<p>(提交阶段)，部分网络出现问题导致部分参与者收不到commit&#x2F;rollback消息的话，就会导致数据不一致。</p>
<ol start="3">
<li><strong>单点问题</strong>︰事务协调者&#x2F;管理者在其中也是一个很重要的角色，如果事务协调者&#x2F;管理者在准备(Prepare)阶段完成之后挂掉的话，事务参与者就会一直卡在提交(Commit)阶段。</li>
</ol>
<h2 id="5-2-3PC-三阶段提交协议"><a href="#5-2-3PC-三阶段提交协议" class="headerlink" title="5.2 3PC(三阶段提交协议)"></a>5.2 3PC(三阶段提交协议)</h2><p>3PC是人们在2PC的基础上做了一些优化得到的。3PC把2PC中的**准备阶段(Prepare)**做了进一步细化，分为2个阶段:</p>
<ol>
<li>询问阶段(CanCommit):这一步不会执行事务操作，只会询问事务参与者能否执行本地数据库事操作。</li>
<li>准备阶段(PreCommit):当所有事物参与者都返回“可执行”之后，事务参与者才会执行本地数据库事务预操作比如写redo log&#x2F;undo log日志。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251102496.png" alt="img"></p>
<p>除此之外，3PC还引入了<strong>超时机制</strong>来避免事务参与者一直阻塞占用资源。</p>
<h2 id="5-3-TCC-补偿事务"><a href="#5-3-TCC-补偿事务" class="headerlink" title="5.3 TCC(补偿事务)"></a>5.3 TCC(补偿事务)</h2><p>简单来说，TCC是 Try、Confirm、Cancel三个词的缩写，它分为三个阶段:</p>
<ol>
<li><p><strong>Try(尝试)阶段</strong>：尝试执行。完成业务检查，并预留好必需的业务资源。</p>
</li>
<li><p><strong>Confirm(确认）阶段</strong>︰确认执行。当所有事务参与者的Try阶段执行成功就会执行Confirm ，Confirm阶段会处理Try阶段预留的业务资源。否则，就会执行Cancel。</p>
</li>
<li><p><strong>Cancel(取消)阶段</strong>：取消执行，释放Try 阶段预留的业务资源。</p>
</li>
</ol>
<p>我们拿转账场景来说:</p>
<ol>
<li>Try(尝试）阶段:在转账场景下，Try要做的事情是就是检查账户余额是否充足，预留的资源就是转账资金。</li>
<li>Confirm(确认）阶段︰如果Try阶段执行成功的话，Confirm阶段就会执行真正的扣钱操作。</li>
<li>Cancel(取消)阶段︰释放Try阶段预留的转账资金。</li>
</ol>
<p>一般情况下，当我们使用 TCC模式的时候需要自己实现 try , confirm,cancel这三个方法，来达到最终—致性。也就是说，正常情况下会执行try , confirm，如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251102564.png" alt="img"><br>出现异常会执行try、cancel，如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251102564.png"><br>因此，<strong>TCC模式不需要依赖于底层数据资源的事务支持，但是需要我们手动实现更多的代码</strong>，属于<strong>侵入业务代码</strong>的一种分布式解决方案。<br>针对TCC的实现，业界也有一些不错的开源框架。不同的框架对于TCC的实现可能略有不同，不过大致思想都一样。</p>
<ol>
<li><strong>ByteTCC</strong>: ByteTCC是基于Try-Confirm-Cancel (TCC)机制的分布式事务管理器的实现。相关阅读:关于如何实现一个TCC分布式事务框架的一点思考</li>
<li><strong>Seata</strong> :Seata是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。</li>
<li>**Hmily **:金融级分布式事务解决方案。</li>
</ol>
<h2 id="5-4-MQ事务"><a href="#5-4-MQ事务" class="headerlink" title="5.4 MQ事务"></a>5.4 MQ事务</h2><p>RocketMQ、 Kafka、Pulsar 、QMQ都提供了事务相关的功能。事务允许事件流应用将消费，处理，生产消息整个过程定义为一个原子操作。<br>以RocketMQ为例：<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251103318.png" alt="img"></p>
<ol>
<li>MQ发送方（比如物流服务）在消息队列上开启一个事务，然后发送一个“半消息”给MQ Server&#x2F;Broker。事务提交之前，半消息对于MQ订阅方&#x2F;消费者（比如第三方通知服务）不可见</li>
<li>“半消息”发送成功的话，MQ发送方就开始执行本地事务。</li>
<li>MQ发送方的本地事务执行成功的话，“半消息”变成正常消息，可以正常被消费。MQ发送方的本地事务执行失败的话，会直接回滚。</li>
</ol>
<p>从上面的流程中可以看出，MQ的事务消息使用的是两阶段提交(2PC)，简单来说就是咱先发送半消息，等本地事务执行成功之后，半消息才变为正常消息。</p>
<p><strong>如果MQ发送方提交或者回滚事务消息时失败怎么办?</strong><br>RocketMQ中的Broker会定期去MQ发送方上反查这个事务的本地事务的执行情况，并根据反查结果决定提交或者回滚这个事务。<br>事务反查机制的实现依赖于我们业务代码实现的对应的接口，比如你要查看创建物流信息的本地事务是否执行成功的话，直接在数据库中查询对应的物流信息是否存在即可。</p>
<p><strong>如果正常消息没有被正确消费怎么办呢?</strong><br>消息消费失败的话，RocketMQ会自动进行消费重试。如果超过最大重试次数这个消息还是没有正确消费,RocketMQ就会认为这个消息有问题，然后将其放到死信队列。<br>进入死信队列的消费一般需要人工处理，手动排查问题。</p>
<p><strong>QMQ</strong>的事务消息就没有RocketMQ 实现的那么复杂了，它借助了数据库自带的事务功能。其核心思想其实就是eBay提出的<strong>本地消息表</strong>方案，将分布式事务拆分成本地事务进行处理。<br>我们维护一个本地消息表用来存放消息发送的状态，保存消息发送情况到本地消息表的操作和业务操作要在一个事务里提交。这样的话，业务执行成功代表消息表也写入成功。<br>然后，我们再单独起一个线程定时轮询消息表，把没处理的消息发送到消息中间件。<br>消息发送成功后，更新消息状态为成功或者直接删除消息。<br>RocketMQ的事务消息方案中，如果消息队列挂掉，数据库事务就无法执行了，整个应用也就挂掉了。<br>QMQ的事务消息方案中，即使消息队列挂了也不会影响数据库事务的执行。<br>因此，QMQ实现的方案能更加适应于大多数业务。不过，这种方法同样适用于其他消息队列，只能说QMQ封装的更好，开箱即用罢了!</p>
<h2 id="5-5-Saga"><a href="#5-5-Saga" class="headerlink" title="5.5 Saga"></a>5.5 Saga</h2><p>Saga属于长事务解决方案，其核心思想史将长事务拆分为多个本地短事务(本地短事务序列)。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251103742.png" alt="img"><br>长事务—&gt;T1,T2~Tn个本地短事务<br>每个短事务都有一个补偿动作—&gt; C1,C2 ~ Cn<br>如果T1,T2～Tn这些短事务都能顺利完成的话，整个事务也就顺利结束，否则，将采取恢复模式。</p>
<p><strong>反向恢复∶</strong></p>
<ol>
<li>简介:如果Ti短事务提交失败，则补偿所有已完成的事务（一直执行Ci对Ti进行补偿)。</li>
<li>执行顺序:T1，T2，…，Ti(失败)，Ci (补偿)，..，C2，C1。</li>
</ol>
<p><strong>正向恢复</strong>︰</p>
<ol>
<li>简介:如果Ti短事务提交失败，则一直对Ti进行重试，直至成功为止。</li>
<li>执行顺序:T1，T2，…，Ti(失败)，Ti(重试) …，Ti+1，..,Tn。</li>
</ol>
<p><strong>优点：</strong><br>和TCC类似，Saga正向操作与补偿操作都需要业务开发者自己实现，因此也属于<strong>侵入业务代码</strong>的一种分布式解决方案。<strong>和TCC很大的一点不同是Saga没有“Try”动作，它的本地事务Ti直接被提交。因此，性能非常高!</strong></p>
<blockquote>
<p>理论上来说，补偿操作一定能够执行成功。不过，当网络出现问题或者服务器宕机的话，补偿操作也会执行失败。这种情况下，往往需要我们进行人工干预。并且，为了能够提高容错性(比如Saga系统本身也可能会崩溃)，保证所有的短事务都得以提交或补偿，我们还需要将这些操作通过日志记录下来(Saga log，类似于数据库的日志机制)。这样，Saga系统恢复之后，我们就知道短事务执行到哪里了或者补偿操作执行到哪里了。</p>
</blockquote>
<p><strong>缺点：</strong><br>因为Saga没有进行“Try”动作预留资源，所以不能保证隔离性。这也是Saga比较大的一个缺点。</p>
<p>针对Saga的实现，业界也有一些不错的开源框架。不同的框架对于Saga的实现可能略有不同，不过大致思想都—样。</p>
<ol>
<li>**ServiceComb Pack **:微服务应用的数据最终—致性解决方案。<br>2.<strong>Seata</strong> :Seata是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务</li>
</ol>
<p>参考：<a href="https://javaguide.cn/">https://javaguide.cn/</a></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title>小白推荐|使用git建立自己的代码仓库</title>
    <url>/2023/04/15/%E5%B0%8F%E7%99%BD%E6%8E%A8%E8%8D%90-%E4%BD%BF%E7%94%A8git%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93/</url>
    <content><![CDATA[<p>👇👇👇👇👇</p>
<span id="more"></span>

<h1 id="1-git"><a href="#1-git" class="headerlink" title="1 git"></a>1 git</h1><h2 id="1-1-什么是git"><a href="#1-1-什么是git" class="headerlink" title="1.1 什么是git"></a>1.1 什么是git</h2><p>版本控制工具，用于团队协作与项目管理</p>
<h2 id="1-2-git-安装教程"><a href="#1-2-git-安装教程" class="headerlink" title="1.2 git 安装教程"></a>1.2 git 安装教程</h2><p>step1：进入git下载官网<a href="https://gitforwindows.org/">https://gitforwindows.org/</a></p>
<p>step2：点击Download</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151314104.png" alt="img"></p>
<p>step3：打开下载好的文件，按照下面图片一步一步安装</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151314714.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311554.png" alt="img"></p>
<p>剩下的一直点Next就完事了！！！看到下面这个界面，点击Finsh,完成安装</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311578.png" alt="img"></p>
<p>step4：检查电脑是否安装成功</p>
<p>Win+R快捷键启动运行，输入cmd，回车打开命令提示符</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151315786.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311594.png" alt="img"></p>
<p>输入git –version，出现版本号，即为安装成功！！！（注意git与–version中间有一个空格）</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311374.png" alt="img"></p>
<h1 id="2-GitHub"><a href="#2-GitHub" class="headerlink" title="2 GitHub"></a>2 GitHub</h1><h2 id="2-1-什么是GitHub"><a href="#2-1-什么是GitHub" class="headerlink" title="2.1 什么是GitHub"></a>2.1 什么是GitHub</h2><p>GitHub是一个使用Git进行软件开发和版本控制的互联网托管服务。</p>
<h2 id="2-2-注册GitHub"><a href="#2-2-注册GitHub" class="headerlink" title="2.2 注册GitHub"></a>2.2 注册GitHub</h2><p>进入GitHub官网（需要打开VPN，翻墙），点Sign up，开始注册</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311811.png" alt="img"></p>
<p>1 输入邮箱</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151315526.png" alt="img"></p>
<p>2 输入密码</p>
<p>提示 password may be compromised(翻译一下就是密码可能泄漏，原因就是密码设置太简单，改一下)</p>
<p>出现下面页面就表示密码可以使用</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151315083.png" alt="img"></p>
<p>3 输入一个用户名</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311981.png" alt="img"></p>
<p>4 输入“n”表示不同意接收订阅消息</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311134.png" alt="img"></p>
<p>5 点击continue，完成验证，点击创建账号（create account）</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311028.png" alt="img"></p>
<p>6 打开你的邮箱，找到GitHub发的邮件，把邮件里的验证码输入到下面框里</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311039.png" alt="img"></p>
<p>7 剩下的就是填一些无关紧要的内容，拉到最下面，直接跳过</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311474.png" alt="img"></p>
<p>8 进入下面这个页面，你就成功开始GitHub之旅了</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311947.png" alt="img"></p>
<h2 id="2-3-创建自己第一个代码仓库"><a href="#2-3-创建自己第一个代码仓库" class="headerlink" title="2.3 创建自己第一个代码仓库"></a>2.3 创建自己第一个代码仓库</h2><p>1 Create repository</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311060.png" alt="img"></p>
<p>2 填写仓库信息</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311216.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151316602.png" alt="img"></p>
<p>3 完成创建，进入仓库页面</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311054.png" alt="img"></p>
<p>有了仓库，下面我们就学习怎么往仓库里上传文件吧！！！</p>
<h2 id="2-4-配合git上传本地文件到自己的GitHub仓库里"><a href="#2-4-配合git上传本地文件到自己的GitHub仓库里" class="headerlink" title="2.4 配合git上传本地文件到自己的GitHub仓库里"></a>2.4 配合git上传本地文件到自己的GitHub仓库里</h2><h3 id="2-4-1-git绑定GitHub账号"><a href="#2-4-1-git绑定GitHub账号" class="headerlink" title="2.4.1 git绑定GitHub账号"></a>2.4.1 git绑定GitHub账号</h3><p>假如我要上传的文件是存放在F:\test下面的note.md文件</p>
<p>在test文件夹下面，右键Git Bash Here</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311402.png" alt="img"></p>
<p>弹出命令框，分别输入下面命令，回车，绑定GitHub的用户名和邮箱</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;你的github用户名&quot;</span></span><br><span class="line"></span><br><span class="line">git config --global user.email <span class="string">&quot;你的github邮箱&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-4-2-绑定SSH"><a href="#2-4-2-绑定SSH" class="headerlink" title="2.4.2 绑定SSH"></a>2.4.2 绑定SSH</h3><p><strong>step1：</strong>同样是在test文件夹下，右键git bash here</p>
<p><strong>step2：</strong>弹出命令框，输入下面命令，生成SSH</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;这里填登录GitHub的邮箱&quot;</span></span><br></pre></td></tr></table></figure>



<p>一直回车，大概按三次，出现下面这个情况就说明成功了</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311033.png" alt="img"></p>
<p>生成的SSH文件会自动放在电脑的C&#x2F;users&#x2F;你的电脑用户名&#x2F;.ssh文件目录下。</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151317389.png" alt="img"></p>
<p><strong>step3：</strong>右键以记事本形式打开“id_rsa.pub”，ctrl+A全选，然后ctrl+C复制全部内容</p>
<p><strong>step4：</strong>回到GitHub，鼠标放在头像上，点击settings</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311071.png" alt="img"></p>
<p>接着点</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311692.png" alt="img"></p>
<p>接着点</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311074.png" alt="img"></p>
<p><strong>step5：</strong>完成之后，回到git bash ,输入下面指令进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br></pre></td></tr></table></figure>



<p>出现下面结果表示绑定成功！！！</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151317222.png" alt="img"></p>
<h3 id="2-4-3-上传文件"><a href="#2-4-3-上传文件" class="headerlink" title="2.4.3 上传文件"></a>2.4.3 上传文件</h3><p>上面我们利用git绑定了自己GitHub的账号名、邮箱以及SSH秘钥(不然每次bash上传就需要输入账号密码，并且绑定SSH有加密功能)，下面介绍如何借助git上传本地文件到自己的GitHub仓库。</p>
<p>以我们创建的第一个代码仓库为例</p>
<p><strong>step1：创建本地存放仓库的文件</strong></p>
<p>在本地先创建一个文件夹，用来存放GitHub上的远程仓库，我这里是F:\test</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311343.png" alt="img"></p>
<p><strong>step2：复制你代码仓库的SSH地址</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311693.png" alt="img"></p>
<p><strong>step3：克隆</strong></p>
<p>回到本地的test文件夹，右键空白处，点git bash here，输入命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> SSH地址</span><br></pre></td></tr></table></figure>

<p>出现下面结果就说明已经将GitHub的远程仓库克隆到了你的本地文件夹！</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311268.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311228.png" alt="img"></p>
<p>进入是下面的内容</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311269.png" alt="img"></p>
<p>假如我想上传的文件夹是note.txt文件，把这个文件放入远程仓库文件夹（first）下，这里我直接在first文件夹下新建个txt文件，进行演示</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311542.png" alt="img"></p>
<p><strong>step4：查看git链接情况，确定远程链接名称+分支名</strong></p>
<p>进入 first文件，空白处右键git bash here</p>
<p>首先，我们要确定远程链接（GitHub仓库的链接）名称以及你要提交到GitHub仓库哪个分支</p>
<p>在first文件下，右键git bash here ，输入指令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311813.png" alt="img"></p>
<p>这里的origin就是远程链接名称</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311174.png" alt="img"></p>
<p>这个就是你要提交的仓库分支</p>
<p>确定远程链接与远程提交分支，我们就可以开始提交文件了（要提交的文件如步骤3描述，note.txt）</p>
<p><strong>step5：将改动先提交到缓冲区</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add .</span><br></pre></td></tr></table></figure>



<p><strong>step6：提交，并添加补充说明</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git commit -m <span class="string">&quot;补充说明&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311749.png" alt="img"></p>
<p><strong>step7：推到远程仓库</strong></p>
<p>首先，远程连接名和远程仓库名我们已经确定，本地仓库名就是你指令界面的蓝色字体部分</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311210.png" alt="img"></p>
<p>使用push 指令提交修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git push 远程链接名 远程仓库分支名：本地仓库分支名</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311281.png" alt="img"></p>
<p><strong>step8：检查是否上传成功</strong></p>
<p>回到GitHub，我们可以看到新添加的note.txt文件已经在自己GitHub仓库里了！！！</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202304151311217.png" alt="img"></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>GitHub</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
  <entry>
    <title>如何将部署在GitHub的博客绑定指定域名</title>
    <url>/2022/05/22/%E5%A6%82%E4%BD%95%E5%B0%86%E9%83%A8%E7%BD%B2%E5%9C%A8GitHub%E7%9A%84%E5%8D%9A%E5%AE%A2%E7%BB%91%E5%AE%9A%E6%8C%87%E5%AE%9A%E5%9F%9F%E5%90%8D/</url>
    <content><![CDATA[<p>🔔 🔔 🔔 🔔 🔔</p>
<span id="more"></span>

<p>前提：我已经将Hexo博客部署在了GitHub，HTTPS为：<a href="https://github.com/MapleFv/MapleFv.github.io.git">https://github.com/MapleFv/MapleFv.github.io.git</a></p>
<p><a href="https://imgtg.com/image/hZOVa"><img src="https://i.imgtg.com/2022/05/22/hZOVa.png" alt="hZOVa.png"></a><a name="YEdIs"></a></p>
<h1 id="1-申请域名"><a href="#1-申请域名" class="headerlink" title="1. 申请域名"></a>1. 申请域名</h1><blockquote>
<p>我用的聚名网，网站地址<a href="https://www.juming.com/">https://www.juming.com/</a><br>这里注册、登录、实名认证…乱起八糟的全部省略，切记一定要<strong>绑定邮箱</strong>，后续通知都是发到邮箱里</p>
</blockquote>
<p><a name="rcRf2"></a></p>
<h2 id="1-1-查询域名"><a href="#1-1-查询域名" class="headerlink" title="1.1 查询域名"></a>1.1 查询域名</h2><p><a href="https://imgtg.com/image/hZooS"><img src="https://i.imgtg.com/2022/05/22/hZooS.png" alt="hZooS.png"></a></p>
<h2 id="1-2-立即注册"><a href="#1-2-立即注册" class="headerlink" title="1.2 立即注册"></a>1.2 立即注册<br /></h2><p><a href="https://imgtg.com/image/hZqrN"><img src="https://i.imgtg.com/2022/05/22/hZqrN.png" alt="hZqrN.png"></a></p>
<h2 id="1-3-付钱"><a href="#1-3-付钱" class="headerlink" title="1.3 付钱"></a>1.3 付钱</h2><p><a name="or9v4"></a></p>
<h2 id="1-4-点击“我的域名”（进入正题）"><a href="#1-4-点击“我的域名”（进入正题）" class="headerlink" title="1.4 点击“我的域名”（进入正题）"></a>1.4 点击“我的域名”（进入正题）</h2><p><a href="https://imgtg.com/image/hZ5GC"><img src="https://i.imgtg.com/2022/05/22/hZ5GC.png" alt="hZ5GC.png"></a></p>
<h2 id="1-5-点击“模板管理”"><a href="#1-5-点击“模板管理”" class="headerlink" title="1.5 点击“模板管理”"></a>1.5 点击“模板管理”</h2><p><a href="https://imgtg.com/image/hZB3L"><img src="https://i.imgtg.com/2022/05/22/hZB3L.png" alt="hZB3L.png"></a></p>
<h2 id="1-6-添加域名模板"><a href="#1-6-添加域名模板" class="headerlink" title="1.6 添加域名模板"></a>1.6 添加域名模板</h2><p><a href="https://imgtg.com/image/hZUii"><img src="https://i.imgtg.com/2022/05/22/hZUii.png" alt="hZUii.png"></a></p>
<h2 id="1-7-等待审核"><a href="#1-7-等待审核" class="headerlink" title="1.7 等待审核"></a>1.7 等待审核</h2><p><a href="https://imgtg.com/image/hZWtX"><img src="https://i.imgtg.com/2022/05/22/hZWtX.png" alt="hZWtX.png"></a></p>
<h2 id="1-8-进入域名管理页面，点击“域名解析”"><a href="#1-8-进入域名管理页面，点击“域名解析”" class="headerlink" title="1.8 进入域名管理页面，点击“域名解析”"></a>1.8 进入域名管理页面，点击“域名解析”<br /></h2><p>点击添加记录</p>
<blockquote>
<p>1、主机记录：就是比如你要让你的域名可以不带www的也可以访问maplefv.top，主机记录为@<br />2、记录类型：防止本地IP有变化，最好选择CNAME类型<br />3、记录值：你的仓库名<br />4、线路类型：无需特殊设置，请保持默认即可！</p>
</blockquote>
<p><a href="https://imgtg.com/image/hZb2t"><img src="https://i.imgtg.com/2022/05/22/hZb2t.png" alt="hZb2t.png"></a></p>
<p>至此，域名准备工作结束<br><a name="mJjVW"></a></p>
<h1 id="2-给git仓库绑定域名"><a href="#2-给git仓库绑定域名" class="headerlink" title="2. 给git仓库绑定域名"></a>2. 给git仓库绑定域名</h1><p>进入仓库，选择Settings,找到Pages，在Custom domain部分添加域名，最后点击“Save”结束<br /></p>
<p><a name="OWwbz"></a></p>
<h1 id="3-本地配置CNAME"><a href="#3-本地配置CNAME" class="headerlink" title="3. 本地配置CNAME"></a>3. 本地配置CNAME</h1><p><a href="https://imgtg.com/image/hZzgj"><img src="https://i.imgtg.com/2022/05/22/hZzgj.png" alt="hZzgj.png"></a></p>
<p><a name="sIZ5Q"></a></p>
<h1 id="4-配置完成，测试"><a href="#4-配置完成，测试" class="headerlink" title="4. 配置完成，测试"></a>4. 配置完成，测试</h1><p>打开浏览器，输入maplefv.top（你的域名）</p>
<p><a href="https://imgtg.com/image/hZFVp"><img src="https://i.imgtg.com/2022/05/22/hZFVp.png" alt="hZFVp.png"></a></p>
]]></content>
      <tags>
        <tag>blogs</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统常见面试题总结</title>
    <url>/2022/05/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>🍍🍍🍍🍍🍍</p>
<span id="more"></span>

<p><a name="aiUvF"></a></p>
<h1 id="1-操作系统基础"><a href="#1-操作系统基础" class="headerlink" title="1. 操作系统基础"></a>1. 操作系统基础</h1><hr>
<p><a name="cIAad"></a></p>
<h2 id="1-1-什么是操作系统"><a href="#1-1-什么是操作系统" class="headerlink" title="1.1 什么是操作系统"></a>1.1 什么是操作系统</h2><hr>
<ol>
<li>操作系统（OS）是管理计算机硬件与软件资源的程序，是计算机的基石</li>
<li>操作系统本质上是一个运行在计算机上的软件程序，用于管理计算机硬件和软件资源</li>
<li>操作系统存在屏蔽了硬件层的复杂性</li>
<li>操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备管理，文件系统的管理以及应用程序的管理<br><a name="r6wnS"></a><h2 id="1-2-系统调用，什么是系统调用"><a href="#1-2-系统调用，什么是系统调用" class="headerlink" title="1.2 系统调用，什么是系统调用"></a>1.2 系统调用，什么是系统调用</h2></li>
</ol>
<hr>
<p>介绍系统调用之前，先了解一下用户状态和系统状态<br />根据进程访问资源的特点，，我们可以将进程在系统上的运行分为两个级别：</p>
<ol>
<li>用户态（user mode）：用户态运行的进程可以直接读取用户程序的数据。</li>
<li>系统态（Kernel mode）：可以简单的理解系统运行的进程或程序几乎可以访问你计算机的任何 资源，不受限制</li>
</ol>
<p>说了用户态和系统态之后，那什么是系统调用呢？<br />我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！<br />也就是说在我们运行的用户程序中，范式与系统态级别的资源有关的操作（如文件管理、进程管理、内存管理等），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。<br />这些系统调用按功能大致分为如下几类：</p>
<ul>
<li>设备管理。完成设备的请求或释放，以及设备启动等功能；</li>
<li>文件管理。完成文件的读、些、创建及删除等功能；</li>
<li>进程控制。完成进程的创建、撤销、阻塞及唤醒等功能；</li>
<li>进程通信。完成进程之间的消息传递或信号传递等功能；</li>
<li>内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。<br><a name="w9bAb"></a><h1 id="2-进程和线程"><a href="#2-进程和线程" class="headerlink" title="2. 进程和线程"></a>2. 进程和线程</h1></li>
</ul>
<hr>
<p><a name="Ug6TM"></a></p>
<h2 id="2-1-进程和线程的区别"><a href="#2-1-进程和线程的区别" class="headerlink" title="2.1 进程和线程的区别"></a>2.1 进程和线程的区别</h2><hr>
<p>一个进程可以有多个线程，多个线程共享进程的堆和方法区（JDK1.8之后的元空间）资源，但是每个线程都有自己的程序计数器、虚拟机栈、本地方法栈</p>
<p><a name="Ljg1v"></a></p>
<h2 id="2-2-进程有哪几种状态"><a href="#2-2-进程有哪几种状态" class="headerlink" title="2.2 进程有哪几种状态?"></a>2.2 进程有哪几种状态?</h2><hr>
<p>一般把进程分为5种状态，这一点和线程很像</p>
<ul>
<li>创建状态（new）</li>
<li>就绪状态（ready）</li>
<li>运行状态（running）</li>
<li>阻塞状态（waiting）</li>
<li>结束状态（terminated）</li>
</ul>
<p><a name="KIphd"></a></p>
<h2 id="2-3-进程间的通信方式"><a href="#2-3-进程间的通信方式" class="headerlink" title="2.3 进程间的通信方式"></a>2.3 进程间的通信方式</h2><hr>
<ol>
<li>管道&#x2F;匿名管道（Pipes）</li>
<li>有名管道（Names Pipes） 先进先出</li>
<li>信号（Signal）</li>
<li>消息队列（Message Queuing）管道与消息队列都是先进先出，不同的是匿名管道存在文件中，有名管道存在于磁盘中，而消息队列存放在内核中。消息队列克服了信号承载信息量少、管道只能承载无格式字节流以及缓冲区大小受限等缺点</li>
<li>信号量（Semaphores）</li>
<li>共享内存（Shared memory）</li>
<li>套接字（Sockets）</li>
</ol>
<p><a name="cZMbv"></a></p>
<h2 id="2-4-线程间的同步的方式"><a href="#2-4-线程间的同步的方式" class="headerlink" title="2.4 线程间的同步的方式"></a>2.4 线程间的同步的方式</h2><hr>
<p>线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步方式：</p>
<ol>
<li>互斥量（Mutex） Java中的synchronized关键字和各种Lock都是这种机制</li>
<li>信号量（Semaphore）</li>
<li>事件（Event）</li>
</ol>
<p><a name="KXXDd"></a></p>
<h2 id="2-5-进程的调度算法"><a href="#2-5-进程的调度算法" class="headerlink" title="2.5 进程的调度算法"></a><br />2.5 进程的调度算法</h2><hr>
<p>为了确定首先执行哪个进程以及最后执行哪个进程以实现最大CPU利用率</p>
<ol>
<li>先到先服务（FCFS）</li>
<li>短作业优先（SJF）</li>
<li>时间片轮转（RR）</li>
<li>多级反馈队列：既能使高优先级的作业得到响应又能使短作业（进程）迅速完成</li>
<li>优先级调度，相同优先级使用FCFS<br><a name="xIvPr"></a><h2 id="2-6-什么是死锁"><a href="#2-6-什么是死锁" class="headerlink" title="2.6 什么是死锁"></a><br />2.6 什么是死锁</h2></li>
</ol>
<hr>
<p>多个进程&#x2F;线程同时被阻塞，他们中的一个或全部都在等待某个资源被释放。由于进程&#x2F;线程被无限期地阻塞，因此程序不可能正常终止。<br><a name="zyRrv"></a></p>
<h2 id="2-7产生死锁的四个条件"><a href="#2-7产生死锁的四个条件" class="headerlink" title="2.7产生死锁的四个条件"></a><br />2.7产生死锁的四个条件</h2><hr>
<p>如果系统中以下四个条件<strong>同时成立</strong>，就能引起死锁：</p>
<ul>
<li>互斥：资源处于非共享模式</li>
<li>占有并等待</li>
<li>非抢占</li>
<li>循环等待</li>
</ul>
<p>2.8 解决死锁的方法</p>
<hr>
<p>预防<br />避免<br />检测<br />解除<br><a name="KfQFN"></a></p>
<h3 id="死锁的预防"><a href="#死锁的预防" class="headerlink" title="死锁的预防"></a>死锁的预防</h3><p>通过破坏死锁产生条件的第二条和第四条<br />1、<strong>静态分配策略</strong>：破坏占有并等待，在执行之前申请到他所需要的全部资源，并且知道他所要的资源都得到满足之后才开始执行；；<br />缺点：严重降低了资源利用率，可能造成一个进程占有了一些几乎不用的资源而使其他需要该资源的进程产生等待的情况。<br />2、<strong>层次分配策略</strong>：破坏循环等待，一个进程得某一次的一个资源后，只能再申请较高一层的资源，当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源<br /><strong>缺点：导致低效的进程运行和资源使用率</strong><br><a name="PLU3d"></a></p>
<h3 id="死锁的避免"><a href="#死锁的避免" class="headerlink" title="死锁的避免"></a><br />死锁的避免</h3><p>我们将系统的状态分为安全状态和不安全状态；通过算法，其中最具代表性的避免死锁算法就是银行家算法，银行家算法用一句话表达就是：当一个进程申请使用资源的时候，银行家算法通过先试探分配给该进程资源，然后通过安全性算法判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入安全状态，就真分配资源给该进程。<br />缺点：要不断检测每个进程对各类资源的占用和申请情况，以及做安全性检查，需要花费较多的时间。</p>
<p><a name="Evn8Z"></a></p>
<h3 id="死锁的检测"><a href="#死锁的检测" class="headerlink" title="死锁的检测"></a>死锁的检测</h3><p>定时地运行一个“死锁检测”程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解决它。<br />死锁检测步骤：</p>
<ol>
<li>如果进程-资源分配图中无环路，则此时系统没有发生死锁</li>
<li>如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁。</li>
<li>如果进程-资源分配图中有环路，且涉及到的资源类有多个资源，此时系统未必会发生死锁。如果能在进程-资源分配图中找出一个 <strong>既不阻塞又非独立的进程</strong> ，该进程能够在有限的时间内归还占有的资源，也就是把边给消除掉了，重复此过程，直到能在有限的时间内 <strong>消除所有的边</strong> ，则不会发生死锁，否则会发生死锁。(消除边的过程类似于 <strong>拓扑排序</strong>)</li>
</ol>
<p><a name="YgtY7"></a></p>
<h3 id="死锁的解除"><a href="#死锁的解除" class="headerlink" title="死锁的解除"></a>死锁的解除</h3><p>当死锁检测程序检测到存在死锁发生时，采取死锁接触操作，让系统从死锁状态中恢复过来，常用的接触死锁方法有以下四种：</p>
<ol>
<li>立即结束所有进程的执行，重新启动操作系统</li>
<li>撤销涉及死锁的进程，解除死锁后继续运行</li>
<li>逐个撤销涉及死锁的进程，回收其资源直至死锁解除</li>
<li>抢占资源<br><a name="s66jD"></a><h1 id="3-操作系统内存管理基础"><a href="#3-操作系统内存管理基础" class="headerlink" title="3. 操作系统内存管理基础"></a>3. 操作系统内存管理基础</h1><a name="M5iuG"></a><h2 id="3-1-操作系统的内存管理主要是做什么？"><a href="#3-1-操作系统的内存管理主要是做什么？" class="headerlink" title="3.1 操作系统的内存管理主要是做什么？"></a>3.1 操作系统的内存管理主要是做什么？</h2></li>
</ol>
<hr>
<p>操作系统的内存管理主要负责内存的分配与回收（malloc函数：申请内存，free函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情<br><a name="CK7pF"></a></p>
<h2 id="3-2-操作系统的内存管理机制了解吗？内存管理有哪几种方式"><a href="#3-2-操作系统的内存管理机制了解吗？内存管理有哪几种方式" class="headerlink" title="3.2 操作系统的内存管理机制了解吗？内存管理有哪几种方式?"></a>3.2 操作系统的内存管理机制了解吗？内存管理有哪几种方式?</h2><hr>
<p>内存管理机制简单分为<strong>连续分配管理方式</strong>和<strong>非连续分配管理方式</strong>两种。连续分配管理方式指为一个用户程序分配一个连续的内存空间，常见的有<strong>块式管理</strong>。非连续分配管理方式指允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如<strong>页式管理和段式管理</strong><br /><strong>块式管理</strong>：如果程序运行需要内存的话，操作系统就分配给他一个内存块<br /><strong>页式管理</strong>：把主内存分为大小相等且固定的一页一页的形式，页较小，相比块式管理的划分力度更小，提高内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址<br /><strong>段式管理</strong>：页式管理虽然提高了内存利用率，但是页式管理其中的页并无任何实际意义。 段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。<br /><strong>段页式管理机制</strong> 。段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 <strong>段页式管理机制</strong> 中段与段之间以及段的内部的都是离散的。<br><a name="G5c7k"></a></p>
<h2 id="3-3-快表和多级页表"><a href="#3-3-快表和多级页表" class="headerlink" title="3.3 快表和多级页表"></a>3.3 快表和多级页表</h2><hr>
<p>在分页内存管理中，很重要的两点是：</p>
<ol>
<li>虚拟地址到物理地址的转换要快。</li>
<li>解决虚拟地址空间大，页表也会很大的问题。<br><a name="tsZ5I"></a><h4 id="快表"><a href="#快表" class="headerlink" title="快表"></a>快表</h4>为了提高虚拟地址到物理地址的转换速度，操作系统在 <strong>页表方案</strong> 基础之上引入了 <strong>快表</strong> 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。</li>
</ol>
<p>使用快表之后的地址转换流程是这样的：</p>
<ol>
<li>根据虚拟地址中的页号查快表；</li>
<li>如果该页在快表中，直接从快表中读取相应的物理地址；</li>
<li>如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；</li>
<li>当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。</li>
</ol>
<p><a name="IpocE"></a></p>
<h4 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h4><p>引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。<br><a name="vPKeV"></a></p>
<h2 id="3-4-分页机制和分段机制的共同点和区别"><a href="#3-4-分页机制和分段机制的共同点和区别" class="headerlink" title="3.4 分页机制和分段机制的共同点和区别"></a>3.4 分页机制和分段机制的共同点和区别</h2><hr>
<ol>
<li><strong>共同点</strong> ：<ul>
<li>分页机制和分段机制都是为了提高内存利用率，减少内存碎片。</li>
<li>页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。</li>
</ul>
</li>
<li><strong>区别</strong> ：<ul>
<li>页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。</li>
<li>分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要<br><a name="cFFyB"></a><h2 id="3-5-逻辑-虚拟-地址和物理地址"><a href="#3-5-逻辑-虚拟-地址和物理地址" class="headerlink" title="3.5 逻辑(虚拟)地址和物理地址"></a>3.5 逻辑(虚拟)地址和物理地址</h2></li>
</ul>
</li>
</ol>
<hr>
<p>比如C语言中指针里存储的数值就可以理解为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。<br><a name="bW4Np"></a></p>
<h2 id="3-6-CPU-寻址了解吗-为什么需要虚拟地址空间"><a href="#3-6-CPU-寻址了解吗-为什么需要虚拟地址空间" class="headerlink" title="3.6 CPU 寻址了解吗?为什么需要虚拟地址空间?"></a>3.6 CPU 寻址了解吗?为什么需要虚拟地址空间?</h2><hr>
<p><strong>使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。</strong><br /><strong>如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。</strong></p>
<p><a name="QJABV"></a></p>
<h1 id="四-虚拟内存"><a href="#四-虚拟内存" class="headerlink" title="四 虚拟内存"></a>四 虚拟内存</h1><p><a name="FvuKs"></a></p>
<h2 id="4-1-什么是虚拟内存-Virtual-Memory"><a href="#4-1-什么是虚拟内存-Virtual-Memory" class="headerlink" title="4.1 什么是虚拟内存(Virtual Memory)?"></a>4.1 什么是虚拟内存(Virtual Memory)?</h2><hr>
<p>虚拟内存可以让程序拥有超过系统物理内存大小的可用内存空间。<br />虚拟内存为每个进程提供了一个一致的、私有的地址空间，他让每个进程产生了一种自己在独享主存的错觉<br><a name="nmTAh"></a></p>
<h2 id="4-2-局部性原理"><a href="#4-2-局部性原理" class="headerlink" title="4.2 局部性原理"></a>4.2 局部性原理</h2><hr>
<p>局部性原理表现在以下两个方面：<br /><strong>时间局部性</strong><br /><strong>空间局部性</strong><br><a name="WndKk"></a></p>
<h2 id="4-3-虚拟存储器"><a href="#4-3-虚拟存储器" class="headerlink" title="4.3 虚拟存储器"></a>4.3 虚拟存储器</h2><hr>
<p>基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其它部分留在外存，就可以启动程序执行。当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大得多的存储器——<strong>虚拟存储器</strong>。<br><a name="rC3eY"></a></p>
<h2 id="4-4-虚拟内存的技术实现"><a href="#4-4-虚拟内存的技术实现" class="headerlink" title="4.4 虚拟内存的技术实现"></a>4.4 虚拟内存的技术实现</h2><hr>
<p><strong>虚拟内存的实现需要建立在离散分配的内存管理方式的基础上虚拟内存的实现需要建立在离散分配的内存管理方式的基础上</strong><br />虚拟内存的实现有以下三种方式：<br /><strong>请求分页存储管理</strong> <br />建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。<br /><strong>请求分段存储管理</strong><br />建立在分段存储管理之上，增加了请求调段功能、分段置换功能。<br /><strong>请求段页式存储管理</strong><br />这里多说一下？很多人容易搞混<strong>请求分页</strong>与<strong>分页存储管理</strong>，两者有何不同呢？<br />请求分页存储管理不要求将作业全部地址空间同时装入主存，可提供虚拟内存<br />分页存储管理却不能提供</p>
<p>不管是上面那种实现方式，我们一般都需要：<br />一定容量的内存和外存<br />却也中断<br />虚拟地址空间</p>
<p><a name="kvh16"></a></p>
<h2 id="4-5-页面置换算法"><a href="#4-5-页面置换算法" class="headerlink" title="4.5 页面置换算法"></a>4.5 页面置换算法</h2><hr>
<p>地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。<br />发生缺页中断时，发现主存没有空闲页面，操作系统就必须在内存选择一个页面将其移出内存，一边为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法。<br /><strong>最佳（Optimal，OPT）页面置换算法</strong>,该算法无法实现。一般作为衡量其他置换算法的方法。<br /><strong>先进先出(first in first out，FIFO)页面置换算法</strong>，总是淘汰先进入内存的页面<br /><strong>最近最久未使用（Least Recently Used,LRU）页面置换算法</strong>。赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，总是淘汰T最大的<br />最少使用（Least Frequently Used）页面置换算法。选择在之前时期使用最少的页面作为淘汰页</p>
]]></content>
      <categories>
        <category>408</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title>正确解决typora+PicGo+GitHub图床配置问题</title>
    <url>/2022/05/25/%E6%AD%A3%E7%A1%AE%E8%A7%A3%E5%86%B3typora+PicGo+GitHub%E5%9B%BE%E5%BA%8A%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>🏇 🏇 🏇 🏇 🏇</p>
<span id="more"></span>

<p>按照本文配置，你可以解决以下出现的问题：</p>
<ol>
<li>typora上传成功，但是PicGo不显示，并且typora图片只显示链接，不显示图片，image load failed</li>
<li>Filed to fetch</li>
<li>“success”:false<h1 id="1-安装必备软件"><a href="#1-安装必备软件" class="headerlink" title="1 安装必备软件"></a>1 安装必备软件</h1>安装最新typora<br>安装PicGo(2.3.0+)<br>创建GitHub仓库，必须设为<strong>公用</strong><h1 id="2-typora配置"><a href="#2-typora配置" class="headerlink" title="2 typora配置"></a>2 typora配置</h1><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251059146.png" alt="img"><br>如果勾选了允许根据YAML设置自动上传图片，很可能出现<strong>PicGo提示上传成功，但是typora不显示图片只显示链接，提示image load failed</strong></li>
</ol>
<h1 id="3-GitHub配置"><a href="#3-GitHub配置" class="headerlink" title="3 GitHub配置"></a>3 GitHub配置</h1><p>申请一个Token，<br>步骤：<br>Settings -&gt; Developer settings -&gt; Personal access tokens<br>生成一个Token记得及时复制保存，刷新之后就没办法查看了，GitHub直接给加密了(艹皿艹 )<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251059599.png" alt="img"></p>
<p> <img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251059476.png" alt="img"></p>
<h1 id="4-PicGo配置"><a href="#4-PicGo配置" class="headerlink" title="4 PicGo配置"></a>4 PicGo配置</h1><blockquote>
<p>每一步都很关键，一步不一样就出问题</p>
</blockquote>
<h2 id="4-1-按图配置，设置为默认图床"><a href="#4-1-按图配置，设置为默认图床" class="headerlink" title="4.1 按图配置，设置为默认图床"></a>4.1 按图配置，设置为默认图床</h2><p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251100820.png" alt="img"><br>重点说一下自定义域名，一定按照下面这个格式来，否则可能出现<strong>image load failed</strong>：<br><strong><a href="https://cdn.jsdelivr.net/gh/%E7%94%A8%E6%88%B7%E5%90%8D/%E4%BB%93%E5%BA%93%E5%90%8D">https://cdn.jsdelivr.net/gh/用户名/仓库名</a></strong></p>
<blockquote>
<p>别听网上其他NT瞎鸡儿指挥，就按照这个格式来，别想着去一个s或者少个&#x2F;，又或者加个&#x2F;&#x2F;，你丫在玩排列组合呢</p>
</blockquote>
<h2 id="4-2-其他设置"><a href="#4-2-其他设置" class="headerlink" title="4.2 其他设置"></a>4.2 其他设置</h2><p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251100942.png" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251100714.png" alt="img"></p>
<blockquote>
<p>否则出现问题：Filed to fetch  或者 “success”:false</p>
</blockquote>
<h1 id="5-测试"><a href="#5-测试" class="headerlink" title="5 测试"></a>5 测试</h1><p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251100372.png" alt="img"></p>
]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>PicGo</tag>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title>理论&amp;算法&amp;协议</title>
    <url>/2022/05/24/%E7%90%86%E8%AE%BA&amp;%E7%AE%97%E6%B3%95&amp;%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p>🍋 🍋 🍋 🍋 🍋</p>
<span id="more"></span>

<h1 id="1-CAP-amp-BASE理论"><a href="#1-CAP-amp-BASE理论" class="headerlink" title="1 CAP &amp; BASE理论"></a>1 CAP &amp; BASE理论</h1><h2 id="1-1-CAP"><a href="#1-1-CAP" class="headerlink" title="1.1 CAP"></a>1.1 CAP</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/22806064/1653009549775-afd92c94-bd01-4ff6-80cf-12eeb81eacf2.png#clientId=uc1e66153-197d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=242&id=ua48ecf63&margin=%5Bobject%20Object%5D&originHeight=366&originWidth=650&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uc049e7ac-ab71-4d94-a4c4-0642a5bf559&title=&width=429"></p>
<ul>
<li><strong>一致性（Consistency）</strong> : 所有节点访问同一份最新的数据副本</li>
<li><strong>可用性（Availability）</strong>: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li>
<li><strong>分区容错性（Partition tolerance）</strong> : 分布式系统出现网络分区的时候，仍然能够对外提供服务。</li>
</ul>
<p><strong>什么是网络分区？</strong></p>
<blockquote>
<p>分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫网络分区。</p>
</blockquote>
<h2 id="1-2-BASE-理论"><a href="#1-2-BASE-理论" class="headerlink" title="1.2 BASE 理论"></a>1.2 BASE 理论</h2><p><strong>BASE</strong> 是 <strong>Basically Available（基本可用）</strong> 、<strong>Soft-state（软状态）</strong> 和 <strong>Eventually Consistent（最终一致性）</strong> 三个短语的缩写。<br><strong>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</strong></p>
<blockquote>
<p>如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。</p>
</blockquote>
<p>因此，AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p>
<h3 id="1-2-1-BASE-理论三要素"><a href="#1-2-1-BASE-理论三要素" class="headerlink" title="1.2.1 BASE 理论三要素"></a>1.2.1 BASE 理论三要素</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/22806064/1653009535653-19f062a2-0699-4b91-8d0d-d37e84916ef7.png#clientId=uc1e66153-197d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=310&id=u5cc5e081&margin=%5Bobject%20Object%5D&originHeight=461&originWidth=612&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=udbc8a978-d11e-4345-9ea9-097ad5bdf38&title=&width=411"></p>
<h4 id="1-基本可用"><a href="#1-基本可用" class="headerlink" title="1. 基本可用"></a>1. 基本可用</h4><p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。<br><strong>什么叫允许损失部分可用性呢？</strong></p>
<ul>
<li><strong>响应时间上的损失</strong>: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。</li>
<li><strong>系统功能上的损失</strong>：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。<h4 id="2-软状态"><a href="#2-软状态" class="headerlink" title="2. 软状态"></a>2. 软状态</h4>软状态指允许系统中的数据存在中间状态（<strong>CAP 理论中的数据不一致</strong>），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。<h4 id=""><a href="#" class="headerlink" title=""></a></h4></li>
</ul>
<ol start="3">
<li>最终一致性<br>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。<blockquote>
<p>分布式一致性的 3 种级别：</p>
<ol>
<li>强一致性 ：系统写入了什么，读出来的就是什么。</li>
<li>弱一致性 ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li>
<li>最终一致性 ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li>
</ol>
</blockquote>
<p>业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。</p>
</li>
</ol>
<p>那实现最终一致性的具体方式是什么呢? </p>
<blockquote>
<ul>
<li><strong>读时修复</strong> : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点 的副本数据不一致，系统就自动修复数据。</li>
<li><strong>写时修复</strong> : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。</li>
<li><strong>异步修复</strong> : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。</li>
</ul>
</blockquote>
<p>比较推荐 <strong>写时修复</strong>，这种方式对性能消耗比较低。</p>
<h3 id="1-2-2-总结"><a href="#1-2-2-总结" class="headerlink" title="1.2.2 总结"></a>1.2.2 总结</h3><p><strong>ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</strong></p>
<h1 id="2-Paxos-算法"><a href="#2-Paxos-算法" class="headerlink" title="2 Paxos 算法"></a>2 Paxos 算法</h1><h2 id="2-1-一致性（Consistency）与共识（Consensus）"><a href="#2-1-一致性（Consistency）与共识（Consensus）" class="headerlink" title="2.1 一致性（Consistency）与共识（Consensus）"></a>2.1 一致性（Consistency）与共识（Consensus）</h2><p>很多人会误把 Paxos 看作是一致性算法，这其实是一个非常大的误区。<br>⚠️注意：<strong>Paxos 不是一致性算法而是共识算法，一致性和共识并不是一个概念。</strong></p>
<h2 id="2-2-Basic-Paxos-算法"><a href="#2-2-Basic-Paxos-算法" class="headerlink" title="2.2 Basic Paxos 算法"></a>2.2 Basic Paxos 算法</h2><p>Basic Paxos 中存在 3 个重要的角色：</p>
<ol>
<li><strong>提议者（Proposer）</strong>：也可以叫做协调者（coordinator），提议者负责接受客户端发起的提议，然后尝试让接受者接受该提议，同时保证即使多个提议者的提议之间产生了冲突，那么算法都能进行下去；</li>
<li><strong>接受者（Acceptor）</strong>：也可以叫做投票员（voter），负责对提议者的提议投票，同时需要记住自己的投票历史；</li>
<li><strong>学习者（Learner）</strong>：如果有超过半数接受者就某个提议达成了共识，那么学习者就需要接受这个提议，并就该提议作出运算，然后将运算结果返回给客户端。</li>
</ol>
<p><img src="https://i.imgtg.com/2022/05/24/hRuiD.png" alt="hRuiD.png"></p>
<h1 id="3-Raft-算法"><a href="#3-Raft-算法" class="headerlink" title="3 Raft 算法"></a>3 Raft 算法</h1><h2 id="3-1-拜占庭将军"><a href="#3-1-拜占庭将军" class="headerlink" title="3.1 拜占庭将军"></a>3.1 拜占庭将军</h2><p>在介绍共识算法之前，先介绍一个简化版拜占庭将军的例子来帮助理解共识算法。<br>假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？<br>解决方案大致可以理解成：先在所有的将军中选出一个大将军，用来做出所有的决定。<br>举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C，如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A，信使回到将军 A 时，将军 A 知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军 A 决定，然后再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。</p>
<h2 id="3-2-共识算法"><a href="#3-2-共识算法" class="headerlink" title="3.2 共识算法"></a>3.2 共识算法</h2><p>共识是可容错系统中的一个基本问题：即使面对故障，服务器也可以在共享状态上达成一致。<br>共识算法允许一组节点像一个整体一样一起工作，即使其中的一些节点出现故障也能够继续工作下去，其正确性主要是源于复制状态机的性质：一组Server的状态机计算相同状态的副本，即使有一部分的Server宕机了它们仍然能够继续运行。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/22806064/1653011800770-9cfd4c90-9e6c-44a2-ae5f-d71faea548d1.png#clientId=uc1e66153-197d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=299&id=u575cb7d9&margin=%5Bobject%20Object%5D&originHeight=652&originWidth=1102&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uf3a7c486-531b-42e6-8bba-99584288318&title=&width=506"><br>一般通过使用复制日志来实现复制状态机。每个Server存储着一份包括命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。<br>因此<strong>共识算法的工作就是保持复制日志的一致性</strong>。服务器上的共识模块从客户端接收命令并将它们添加到日志中。它与其他服务器上的共识模块通信，以确保即使某些服务器发生故障，每个日志最终包含相同顺序的请求。一旦命令被正确地复制，它们就被称为已提交。每个服务器的状态机按照日志顺序处理已提交的命令，并将输出返回给客户端，因此，这些服务器形成了一个单一的、高度可靠的状态机。<br>适用于实际系统的共识算法通常具有以下特性：</p>
<ul>
<li><strong>安全</strong>。确保在非拜占庭条件（也就是上文中提到的简易版拜占庭）下的安全性，包括网络延迟、分区、包丢失、复制和重新排序。</li>
<li><strong>高可用</strong>。只要大多数服务器都是可操作的，并且可以相互通信，也可以与客户端进行通信，那么这些服务器就可以看作完全功能可用的。因此，一个典型的由五台服务器组成的集群可以容忍任何两台服务器端故障。假设服务器因停止而发生故障；它们稍后可能会从稳定存储上的状态中恢复并重新加入集群。</li>
<li><strong>一致性不依赖时序</strong>。错误的时钟和极端的消息延迟，在最坏的情况下也只会造成可用性问题，而不会产生一致性问题。</li>
<li>在集群中大多数服务器响应，命令就可以完成，不会被少数运行缓慢的服务器来影响整体系统性能。<h2 id="3-3-基础"><a href="#3-3-基础" class="headerlink" title="3.3 基础"></a>3.3 基础</h2></li>
</ul>
<h3 id="3-3-1-节点类型"><a href="#3-3-1-节点类型" class="headerlink" title="3.3.1 节点类型"></a>3.3.1 节点类型</h3><p>一个 Raft 集群包括若干服务器，以典型的 5 服务器集群举例。在任意的时间，每个服务器一定会处于以下三个状态中的一个：</p>
<ul>
<li>Leader：负责发起心跳，响应客户端，创建日志，同步日志。</li>
<li>Candidate：Leader 选举过程中的临时角色，由 Follower 转化而来，发起投票参与竞选。</li>
<li>Follower：接受 Leader 的心跳和日志同步数据，投票给 Candidate。</li>
</ul>
<h3 id="3-3-2-任期"><a href="#3-3-2-任期" class="headerlink" title="3.3.2 任期"></a>3.3.2 任期</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/22806064/1653012346940-febbf284-c392-4c64-a61e-3ea337f9a50b.png#clientId=uc1e66153-197d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=187&id=u923b72a5&margin=%5Bobject%20Object%5D&originHeight=236&originWidth=576&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u1e107231-1238-487d-9fc2-6172d881baf&title=&width=457"><br>如图所示，raft 算法将时间划分为任意长度的任期（term），任期用连续的数字表示，看作当前 term 号。每一个任期的开始都是一次选举，在选举开始时，一个或多个 Candidate 会尝试成为 Leader。如果一个 Candidate 赢得了选举，它就会在该任期内担任 Leader。如果没有选出 Leader，将会开启另一个任期，并立刻开始下一次选举。raft 算法保证在给定的一个任期最少要有一个 Leader。<br>每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号；如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值。如果一个 Candidate 或者 Leader 发现自己的 term 过期了，他会立即退回成 Follower。如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求。</p>
<h3 id="3-3-3-日志"><a href="#3-3-3-日志" class="headerlink" title="3.3.3 日志"></a>3.3.3 日志</h3><ul>
<li>entry：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为&lt;term,index,cmd&gt;其中 cmd 是可以应用到状态机的操作。</li>
<li>log：由 entry 构成的数组，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。<h2 id="3-4-领导人选举"><a href="#3-4-领导人选举" class="headerlink" title="3.4 领导人选举"></a>3.4 领导人选举</h2></li>
</ul>
<p>raft 使用心跳机制来触发 Leader 的选举。</p>
<h2 id="3-5-日志复制"><a href="#3-5-日志复制" class="headerlink" title="3.5 日志复制"></a>3.5 日志复制</h2><p>一旦选出了 Leader，它就开始接受客户端的请求。每一个客户端的请求都包含一条需要被复制状态机（Replicated State Mechine）执行的命令。</p>
<h2 id="3-6-安全性"><a href="#3-6-安全性" class="headerlink" title="3.6 安全性"></a>3.6 安全性</h2><h3 id="3-6-1-选举限制"><a href="#3-6-1-选举限制" class="headerlink" title="3.6.1 选举限制"></a>3.6.1 选举限制</h3><p>Leader 需要保证自己存储全部已经提交的日志条目。这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。</p>
<h3 id="3-6-2-节点崩溃"><a href="#3-6-2-节点崩溃" class="headerlink" title="3.6.2 节点崩溃"></a>3.6.2 节点崩溃</h3><p>如果 Leader 崩溃，集群中的节点在 electionTimeout 时间内没有收到 Leader 的心跳信息就会触发新一轮的选主，在选主期间整个集群对外是不可用的。</p>
<h3 id="3-6-3-时间与可用性"><a href="#3-6-3-时间与可用性" class="headerlink" title="3.6.3 时间与可用性"></a>3.6.3 时间与可用性</h3><p>raft 的要求之一就是安全性不依赖于时间：系统不能仅仅因为一些事件发生的比预想的快一些或者慢一些就产生错误。</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>RPC</title>
    <url>/2022/05/24/RPC/</url>
    <content><![CDATA[<p>🍋 🍋 🍋 🍋 🍋</p>
<span id="more"></span>

<h1 id="1-Dubbo知识点-amp-面试题总结"><a href="#1-Dubbo知识点-amp-面试题总结" class="headerlink" title="1 Dubbo知识点&amp;面试题总结"></a>1 Dubbo知识点&amp;面试题总结</h1><h2 id="1-1-RPC基础"><a href="#1-1-RPC基础" class="headerlink" title="1.1 RPC基础"></a>1.1 RPC基础</h2><h3 id="1-1-1-何为-RPC"><a href="#1-1-1-何为-RPC" class="headerlink" title="1.1.1 何为 RPC?"></a>1.1.1 何为 RPC?</h3><p><strong>RPC（Remote Procedure Call）</strong> 即远程过程调用，通过名字我们就能看出 RPC 关注的是远程调用而非本地调用。<br><strong>为什么要 RPC ？</strong> 因为，两个不同的服务器上的服务提供的方法不在一个内存空间，所以，需要通过网络编程才能传递方法调用所需要的参数。<br><strong>RPC 能帮助我们做什么呢？</strong> 简单来说，通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。</p>
<blockquote>
<p>举个例子：两个不同的服务 A、B 部署在两台不同的机器上，服务 A 如果想要调用服务 B 中的某个方法的话就可以通过 RPC 来做。</p>
</blockquote>
<h3 id="1-1-2-RPC-的原理是什么"><a href="#1-1-2-RPC-的原理是什么" class="headerlink" title="1.1.2 RPC 的原理是什么?"></a>1.1.2 RPC 的原理是什么?</h3><p>们可以将整个 RPC的 核心功能看作是下面👇 6 个部分实现的：</p>
<ol>
<li><strong>客户端（服务消费端）</strong> ：调用远程方法的一端。</li>
<li><strong>客户端 Stub（桩）</strong> ： 这其实就是一代理类。代理类主要做的事情很简单，就是把你调用方法、类、方法参数等信息传递到服务端。</li>
<li><strong>网络传输</strong> ： 网络传输就是你要把你调用的方法的信息比如说参数啊这些东西传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有很多种比如最近基本的 Socket或者性能以及封装更加优秀的 Netty（推荐）。</li>
<li><strong>服务端 Stub（桩）</strong> ：这个桩就不是代理类了。我觉得理解为桩实际不太好，大家注意一下就好。这里的服务端 Stub 实际指的就是接收到客户端执行方法的请求后，去指定对应的方法然后返回结果给客户端的类。</li>
<li><strong>服务端（服务提供端）</strong> ：提供远程方法的一端。</li>
</ol>
<p>具体原理图如下<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/22806064/1653014700392-e71bae2c-80d2-4174-8ece-02bc2563c109.jpeg#clientId=udafac82c-fce2-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue5509fe0&margin=%5Bobject%20Object%5D&originHeight=317&originWidth=499&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ue8a0754f-9672-4f1e-b090-640e7534098&title="></p>
<ol>
<li>客户端（client）以本地调用的方式调用远程服务；</li>
<li>客户端 Stub（client stub） 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体（序列化）：RpcRequest；</li>
<li>客户端 Stub（client stub） 找到远程服务的地址，并将消息发送到服务提供端；</li>
<li>服务端 Stub（桩）收到消息将消息反序列化为Java对象: RpcRequest；</li>
<li>服务端 Stub（桩）根据RpcRequest中的类、方法、方法参数等信息调用本地的方法；</li>
<li>服务端 Stub（桩）得到方法执行结果并将组装成能够进行网络传输的消息体：RpcResponse（序列化）发送至消费方；</li>
<li>客户端 Stub（client stub）接收到消息并将消息反序列化为Java对象:RpcResponse ，这样也就得到了最终结果。over!</li>
</ol>
<h2 id="1-2-Dubbo基础"><a href="#1-2-Dubbo基础" class="headerlink" title="1.2 Dubbo基础"></a>1.2 Dubbo基础</h2><h3 id="1-2-1-什么是-Dubbo"><a href="#1-2-1-什么是-Dubbo" class="headerlink" title="1.2.1 什么是 Dubbo?"></a>1.2.1 什么是 Dubbo?</h3><p>Apache Dubbo是一款高性能、轻量级的开源 Java RPC 框架。<br>Dubbo 提供了六大核心能力</p>
<ol>
<li><p>面向接口代理的高性能RPC调用。</p>
</li>
<li><p>智能容错和负载均衡。</p>
</li>
<li><p>服务自动注册和发现。</p>
</li>
<li><p>高度可扩展能力。</p>
</li>
<li><p>运行期流量调度。</p>
</li>
<li><p>可视化的服务治理与运维。</p>
<h3 id="1-2-2-为什么要用-Dubbo-Dubbo-帮助我们解决了什么问题呢？"><a href="#1-2-2-为什么要用-Dubbo-Dubbo-帮助我们解决了什么问题呢？" class="headerlink" title="1.2.2 为什么要用 Dubbo? Dubbo 帮助我们解决了什么问题呢？"></a>1.2.2 为什么要用 Dubbo? <strong>Dubbo 帮助我们解决了什么问题呢？</strong></h3></li>
<li><p><strong>负载均衡</strong> ： 同一个服务部署在不同的机器时该调用哪一台机器上的服务。</p>
</li>
<li><p><strong>服务调用链路生成</strong> ： 随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。Dubbo 可以为我们解决服务之间互相是如何调用的。</p>
</li>
<li><p><strong>服务访问压力以及时长统计、资源调度和治理</strong> ：基于访问压力实时管理集群容量，提高集群利用率。</p>
<blockquote>
<p>另外，Dubbo 除了能够应用在分布式系统中，也可以应用在现在比较火的微服务系统中。不过，由于 Spring Cloud 在微服务中应用更加广泛，所以，我觉得一般我们提 Dubbo 的话，大部分是分布式系统的情况。</p>
</blockquote>
</li>
</ol>
<h2 id="1-3-分布式基础"><a href="#1-3-分布式基础" class="headerlink" title="1.3 分布式基础"></a>1.3 分布式基础</h2><h3 id="1-3-1-什么是分布式"><a href="#1-3-1-什么是分布式" class="headerlink" title="1.3.1 什么是分布式?"></a>1.3.1 什么是分布式?</h3><p>分布式或者说 SOA 分布式重要的就是面向服务，说简单的分布式就是我们把整个系统拆分成不同的服务然后将这些服务放在不同的服务器上减轻单体服务的压力提高并发量和性能。</p>
<h3 id="1-3-2-为什么要分布式"><a href="#1-3-2-为什么要分布式" class="headerlink" title="1.3.2 为什么要分布式?"></a>1.3.2 为什么要分布式?</h3><p>从开发角度来讲单体应用的代码都集中在一起，而分布式系统的代码根据业务被拆分。所以，每个团队可以负责一个服务的开发，这样提升了开发效率。另外，代码根据业务拆分之后更加便于维护和扩展。<br>把整个系统拆分成不同的服务&#x2F;系统，然后每个服务&#x2F;系统 单独部署在一台服务器上，很大程度上提高了系统性能</p>
<h2 id="1-4-Dubbo-架构"><a href="#1-4-Dubbo-架构" class="headerlink" title="1.4 Dubbo 架构"></a>1.4 Dubbo 架构</h2><h3 id="1-4-1-Dubbo-架构中的核心角色有哪些？"><a href="#1-4-1-Dubbo-架构中的核心角色有哪些？" class="headerlink" title="1.4.1 Dubbo 架构中的核心角色有哪些？"></a>1.4.1 Dubbo 架构中的核心角色有哪些？</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/22806064/1653015548796-d22a0cd7-74f8-476d-9bfa-6224c8f63fb5.jpeg#clientId=udafac82c-fce2-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u88489783&margin=%5Bobject%20Object%5D&originHeight=330&originWidth=500&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ub65eb466-59f3-4fb1-8f09-e9eacbb928a&title="></p>
<ul>
<li><strong>Container：</strong> 服务运行容器，负责加载、运行服务提供者。必须。</li>
<li><strong>Provider：</strong> 暴露服务的服务提供方，会向注册中心注册自己提供的服务。必须。</li>
<li><strong>Consumer：</strong> 调用远程服务的服务消费方，会向注册中心订阅自己所需的服务。必须。</li>
<li><strong>Registry：</strong> 服务注册与发现的注册中心。注册中心会返回服务提供者地址列表给消费者。非必须。</li>
<li><strong>Monitor：</strong> 统计服务的调用次数和调用时间的监控中心。服务消费者和提供者会定时发送统计数据到监控中心。 非必须<h3 id="1-4-2-Dubbo-中的-Invoker-概念了解么？"><a href="#1-4-2-Dubbo-中的-Invoker-概念了解么？" class="headerlink" title="1.4.2 Dubbo 中的 Invoker 概念了解么？"></a>1.4.2 Dubbo 中的 Invoker 概念了解么？</h3></li>
</ul>
<p>简单来说，Invoker 就是 Dubbo 对远程调用的抽象。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/22806064/1653015772799-608e5020-0ddb-466b-ba69-23296d598e57.jpeg#clientId=udafac82c-fce2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=299&id=u466dc0a0&margin=%5Bobject%20Object%5D&originHeight=402&originWidth=614&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u707d5abb-f20d-483e-b18c-a638b4eaba8&title=&width=456"><br>按照 Dubbo 官方的话来说，Invoker 分为</p>
<ul>
<li>服务提供 Invoker</li>
<li>服务消费 Invoker</li>
</ul>
<p>当我们需要调用一个远程方法，我们需要动态代理来屏蔽远程调用的细节，我们屏蔽掉的这些细节是依赖Invoker，Invoker实现了真正的远程服务调用。</p>
<h3 id="1-4-3-Dubbo-的工作原理了解么？"><a href="#1-4-3-Dubbo-的工作原理了解么？" class="headerlink" title="1.4.3 Dubbo 的工作原理了解么？"></a>1.4.3 Dubbo 的工作原理了解么？</h3><p>图是 Dubbo 的整体设计，从下至上分为十层，各层均为单向依赖。</p>
<blockquote>
<p>左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。</p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/22806064/1653016045649-c8756765-a66e-44ec-8045-83ce53cda79d.jpeg#clientId=udafac82c-fce2-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3b78a7a9&margin=%5Bobject%20Object%5D&originHeight=674&originWidth=900&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u177cad61-df10-42a0-82ac-75c9ed5f48e&title="></p>
<ul>
<li><strong>config 配置层</strong>：Dubbo相关的配置。支持代码配置，同时也支持基于 Spring 来做配置，以 ServiceConfig, ReferenceConfig 为中心</li>
<li><strong>proxy 服务代理层</strong>：调用远程方法像调用本地的方法一样简单的一个关键，真实调用过程依赖代理类，以 ServiceProxy 为中心。</li>
<li><strong>registry 注册中心层</strong>：封装服务地址的注册与发现。</li>
<li><strong>cluster 路由层</strong>：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心。</li>
<li><strong>monitor 监控层</strong>：RPC 调用次数和调用时间监控，以 Statistics 为中心。</li>
<li><strong>protocol 远程调用层</strong>：封装 RPC 调用，以 Invocation, Result 为中心。</li>
<li><strong>exchange 信息交换层</strong>：封装请求响应模式，同步转异步，以 Request, Response 为中心。</li>
<li><strong>transport 网络传输层</strong>：抽象 mina 和 netty 为统一接口，以 Message 为中心。</li>
<li><strong>serialize 数据序列化层</strong> ：对需要在网络传输的数据进行序列化。<h3 id="1-4-4-Dubbo-的-SPI-机制了解么？-如何扩展-Dubbo-中的默认实现？"><a href="#1-4-4-Dubbo-的-SPI-机制了解么？-如何扩展-Dubbo-中的默认实现？" class="headerlink" title="1.4.4 Dubbo 的 SPI 机制了解么？ 如何扩展 Dubbo 中的默认实现？"></a>1.4.4 Dubbo 的 SPI 机制了解么？ 如何扩展 Dubbo 中的默认实现？</h3></li>
</ul>
<p>SPI（Service Provider Interface） 机制被大量用在开源项目中，它可以帮助我们动态寻找服务&#x2F;功能（比如负载均衡策略）的实现。<br>SPI具体原理：我们将接口的实现类放在配置文件中，我们在程序运行过程中读取配置文件，通过反射加载实现类。这样我们可以在运行的时候，动态替换接口的实现类。和IoC的解耦思想是类似的。</p>
<h3 id="1-4-5-Dubbo-的微内核架构了解吗？"><a href="#1-4-5-Dubbo-的微内核架构了解吗？" class="headerlink" title="1.4.5 Dubbo 的微内核架构了解吗？"></a>1.4.5 Dubbo 的微内核架构了解吗？</h3><p>Dubbo 采用 微内核（Microkernel） + 插件（Plugin） 模式，简单来说就是微内核架构。微内核只负责组装插件。<br>微内核架构包含两类组件：<strong>核心系统（core system）</strong> 和 <strong>插件模块（plug-in modules）</strong>。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/22806064/1653016628926-c7e09038-b309-4e4e-b207-4f62893a12e1.png#clientId=udafac82c-fce2-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5dba7cca&margin=%5Bobject%20Object%5D&originHeight=267&originWidth=397&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ub437bffd-98f1-4b77-ba3e-91d891ce8bf&title="><br>核心系统提供系统所需核心能力，插件模块可以扩展系统的功能。</p>
<h3 id="1-4-6-关于Dubbo架构的一些自测小问题"><a href="#1-4-6-关于Dubbo架构的一些自测小问题" class="headerlink" title="1.4.6 关于Dubbo架构的一些自测小问题"></a>1.4.6 关于Dubbo架构的一些自测小问题</h3><h4 id="注册中心的作用了解么？"><a href="#注册中心的作用了解么？" class="headerlink" title="注册中心的作用了解么？"></a>注册中心的作用了解么？</h4><p>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互。</p>
<h4 id="服务提供者宕机后，注册中心会做什么？"><a href="#服务提供者宕机后，注册中心会做什么？" class="headerlink" title="服务提供者宕机后，注册中心会做什么？"></a>服务提供者宕机后，注册中心会做什么？</h4><p>注册中心会立即推送事件通知消费者</p>
<h4 id="监控中心的作用呢？"><a href="#监控中心的作用呢？" class="headerlink" title="监控中心的作用呢？"></a>监控中心的作用呢？</h4><p>监控中心负责统计各服务调用次数，调用时间等。</p>
<h4 id="注册中心和监控中心都宕机的话，服务都会挂掉吗？"><a href="#注册中心和监控中心都宕机的话，服务都会挂掉吗？" class="headerlink" title="注册中心和监控中心都宕机的话，服务都会挂掉吗？"></a>注册中心和监控中心都宕机的话，服务都会挂掉吗？</h4><p>不会。两者都宕机也不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表。注册中心和监控中心都是可选的，服务消费者可以直连服务提供者。</p>
<h2 id="1-5-Dubbo-的负载均衡策略"><a href="#1-5-Dubbo-的负载均衡策略" class="headerlink" title="1.5 Dubbo 的负载均衡策略"></a>1.5 Dubbo 的负载均衡策略</h2><h3 id="1-5-1-什么是负载均衡？"><a href="#1-5-1-什么是负载均衡？" class="headerlink" title="1.5.1 什么是负载均衡？"></a>1.5.1 什么是负载均衡？</h3><p>系统中某个服务访问量特别大，我们就将这个服务部署在了多台服务器上，当客户端发起请求的时候，多台服务器就可以处理这个请求，如何正确选择处理请求的服务器就很关键。负载均衡就是为了避免单个服务器响应同意请求，容易造成服务器宕机、崩溃等问题。</p>
<h3 id="1-5-2-Dubbo-提供的负载均衡策略有哪些？"><a href="#1-5-2-Dubbo-提供的负载均衡策略有哪些？" class="headerlink" title="1.5.2 Dubbo 提供的负载均衡策略有哪些？"></a>1.5.2 Dubbo 提供的负载均衡策略有哪些？</h3><p>在 Dubbo 中，所有负载均衡实现类均继承自 AbstractLoadBalance，该类实现了 LoadBalance 接口，并封装了一些公共的逻辑。<br>AbstractLoadBalance 的实现类有下面这些：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/22806064/1653116253920-5376077d-e4c0-4e87-a0a3-f992a70735ed.png#clientId=ub260b10c-a61e-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=261&id=ub2965390&margin=%5Bobject%20Object%5D&originHeight=308&originWidth=611&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u458693b4-7cc0-4f90-a8b7-f311408fc81&title=&width=518"></p>
<h4 id="RandomLoadBalance"><a href="#RandomLoadBalance" class="headerlink" title="RandomLoadBalance"></a>RandomLoadBalance</h4><p>根据权重随机选择（对加权随机算法的实现）。这是Dubbo默认采用的一种负载均衡策略。</p>
<h4 id="LeastActiveLoadBalance-最小活跃数负载均衡"><a href="#LeastActiveLoadBalance-最小活跃数负载均衡" class="headerlink" title="LeastActiveLoadBalance  最小活跃数负载均衡"></a>LeastActiveLoadBalance  <strong>最小活跃数负载均衡</strong></h4><p>Dubbo 就认为谁的活跃数越少，谁的处理速度就越快，性能也越好，这样的话，我就优先把请求给活跃数少的服务提供者处理。<br>如果有多个服务提供者的活跃数相等就再走一遍 RandomLoadBalance</p>
<h4 id="ConsistentHashLoadBalance-一致性Hash负载均衡策略"><a href="#ConsistentHashLoadBalance-一致性Hash负载均衡策略" class="headerlink" title="ConsistentHashLoadBalance   一致性Hash负载均衡策略"></a>ConsistentHashLoadBalance   <strong>一致性Hash负载均衡策略</strong></h4><p>ConsistentHashLoadBalance 中没有权重的概念，具体是哪个服务提供者处理请求是由你的请求的参数决定的，也就是说相同参数的请求总是发到同一个服务提供者。<br>另外，Dubbo 为了避免数据倾斜问题（节点不够分散，大量请求落到同一节点），还引入了虚拟节点的概念。通过虚拟节点可以让节点更加分散，有效均衡各个节点的请求量。</p>
<h4 id="RoundRobinLoadBalance-加权轮询负载均衡"><a href="#RoundRobinLoadBalance-加权轮询负载均衡" class="headerlink" title="RoundRobinLoadBalance   加权轮询负载均衡"></a>RoundRobinLoadBalance   加权轮询负载均衡</h4><p>轮询就是把请求依次分配给每个服务提供者。加权轮询就是在轮询的基础上，让更多的请求落到权重更大的服务提供者上。比如假如有两个提供相同服务的服务器 S1,S2，S1的权重为7，S2的权重为3。<br>如果我们有 10 次请求，那么 7 次会被 S1处理，3次被 S2处理。</p>
<h2 id="1-6-Dubbo序列化协议"><a href="#1-6-Dubbo序列化协议" class="headerlink" title="1.6 Dubbo序列化协议"></a>1.6 Dubbo序列化协议</h2><h3 id="1-6-1-Dubbo-支持哪些序列化方式呢？"><a href="#1-6-1-Dubbo-支持哪些序列化方式呢？" class="headerlink" title="1.6.1 Dubbo 支持哪些序列化方式呢？"></a>1.6.1 Dubbo 支持哪些序列化方式呢？</h3><p>Dubbo 支持多种序列化方式：JDK自带的序列化、hessian2、JSON、Kryo、FST、Protostuff，ProtoBuf等等。<br>Dubbo 默认使用的序列化方式是 hession2。</p>
<h3 id="1-6-2-谈谈你对这些序列化协议了解？"><a href="#1-6-2-谈谈你对这些序列化协议了解？" class="headerlink" title="1.6.2 谈谈你对这些序列化协议了解？"></a>1.6.2 谈谈你对这些序列化协议了解？</h3><p>一般我们不会直接使用 JDK 自带的序列化方式。主要原因有两个：</p>
<ol>
<li><strong>不支持跨语言调用</strong> : 如果调用的是其他语言开发的服务的时候就不支持了。</li>
<li><strong>性能差</strong> ：相比于其他序列化框架性能更低，主要原因是序列化之后的字节数组体积较大，导致传输成本加大。</li>
</ol>
<p>JSON 序列化由于性能问题，我们一般也不会考虑使用。</p>
<p>像 Protostuff，ProtoBuf、hessian2这些都是跨语言的序列化方式，如果有跨语言需求的话可以考虑使用。<br>Kryo和FST这两种序列化方式是 Dubbo 后来才引入的，性能非常好。不过，这两者都是专门针对 Java 语言的。</p>
<h1 id="2-服务之间的调用为啥不直接用-HTTP-而用-RPC？"><a href="#2-服务之间的调用为啥不直接用-HTTP-而用-RPC？" class="headerlink" title="2 服务之间的调用为啥不直接用 HTTP 而用 RPC？"></a>2 服务之间的调用为啥不直接用 HTTP 而用 RPC？</h1><h2 id="1-什么是-RPC-RPC原理是什么"><a href="#1-什么是-RPC-RPC原理是什么" class="headerlink" title="1 什么是 RPC?RPC原理是什么?"></a>1 什么是 RPC?RPC原理是什么?</h2><h3 id="什么是-RPC？"><a href="#什么是-RPC？" class="headerlink" title="什么是 RPC？"></a><strong>什么是 RPC？</strong></h3><p>RPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。比如两个不同的服务 A、B 部署在两台不同的机器上，那么服务 A 如果想要调用服务 B 中的某个方法该怎么办呢？使用 HTTP请求 当然可以，但是可能会比较慢而且一些优化做的并不好。 RPC 的出现就是为了解决这个问题。</p>
<h3 id="RPC原理是什么？"><a href="#RPC原理是什么？" class="headerlink" title="RPC原理是什么？"></a><strong>RPC原理是什么？</strong></h3><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/22806064/1653144618623-4c2d1b86-6741-4398-a0ee-dc0d7bf5e188.jpeg#clientId=u725b0552-5441-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc9df02f5&margin=%5Bobject%20Object%5D&originHeight=317&originWidth=499&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u7190347b-708c-4b32-baa7-52b8549a846&title="></p>
<ol>
<li><strong>客户端（服务消费端）</strong> ：调用远程方法的一端。</li>
<li><strong>客户端 Stub（桩）</strong> ： 这其实就是一代理类。代理类主要做的事情很简单，就是把你调用方法、类、方法参数等信息传递到服务端。</li>
<li><strong>网络传输</strong> ： 网络传输就是你要把你调用的方法的信息比如说参数啊这些东西传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有很多种比如最近基本的 Socket或者性能以及封装更加优秀的 Netty（推荐）。</li>
<li><strong>服务端 Stub（桩）</strong> ：这个桩就不是代理类了。我觉得理解为桩实际不太好，大家注意一下就好。这里的服务端 Stub 实际指的就是接收到客户端执行方法的请求后，去指定对应的方法然后返回结果给客户端的类。</li>
<li><strong>服务端（服务提供端）</strong> ：提供远程方法的一端。<h3 id="RPC-解决了什么问题？"><a href="#RPC-解决了什么问题？" class="headerlink" title="RPC 解决了什么问题？"></a>RPC 解决了什么问题？</h3></li>
</ol>
<p><strong>让分布式或者微服务系统中不同服务之间的调用像本地调用一样简单。</strong></p>
<h3 id="常见的-RPC-框架总结"><a href="#常见的-RPC-框架总结" class="headerlink" title="常见的 RPC 框架总结?"></a>常见的 RPC 框架总结?</h3><ul>
<li><strong>Dubbo:</strong> Dubbo是 阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成。目前 Dubbo 已经成为 Spring Cloud Alibaba 中的官方组件。</li>
<li><strong>gRPC</strong> ：gRPC是可以在任何环境中运行的现代开源高性能RPC框架。它可以通过可插拔的支持来有效地连接数据中心内和跨数据中心的服务，以实现负载平衡，跟踪，运行状况检查和身份验证。它也适用于分布式计算的最后一英里，以将设备，移动应用程序和浏览器连接到后端服务。</li>
<li><strong>Hessian：</strong> Hessian是一个轻量级的remoting on http工具，使用简单的方法提供了RMI的功能。 相比WebService，Hessian更简单、快捷。采用的是二进制RPC协议，因为采用的是二进制协议，所以它很适合于发送二进制数据。</li>
<li><strong>Thrift：</strong> Apache Thrift是Facebook开源的跨语言的RPC通信框架，目前已经捐献给Apache基金会管理，由于其跨语言特性和出色的性能，在很多互联网公司得到应用，有能力的公司甚至会基于thrift研发一套分布式服务框架，增加诸如服务注册、服务发现等功能。</li>
</ul>
<h2 id="2-既有-HTTP-为啥用-RPC-进行服务调用"><a href="#2-既有-HTTP-为啥用-RPC-进行服务调用" class="headerlink" title="2 既有 HTTP ,为啥用 RPC 进行服务调用?"></a>2 既有 HTTP ,为啥用 RPC 进行服务调用?</h2><p>RPC 只是一种概念、一种设计，就是为了解决 <strong>不同服务之间的调用问题</strong>, 它一般会包含有 <strong>传输协议</strong> 和 <strong>序列化协议</strong> 这两个。<br>但是，HTTP 是一种协议，RPC框架可以使用 HTTP协议作为传输协议或者直接使用TCP作为传输协议，使用不同的协议一般也是为了适应不同的场景。</p>
<h3 id="HTTP-和-TCP"><a href="#HTTP-和-TCP" class="headerlink" title="HTTP 和 TCP"></a>HTTP 和 TCP</h3><blockquote>
<p>HTTP 属于应用层协议，它会基于TCP&#x2F;IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。HTTP协议工作于客户端-服务端架构上。浏览器作为HTTP客户端通过 URL 向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。HTTP协议建立在 TCP 协议之上。</p>
</blockquote>
<blockquote>
<p>传输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。TCP是传输层协议，主要解决数据如何在网络中传输。相比于UDP,TCP 提供的是面向连接的，可靠的数据传输服务。</p>
</blockquote>
<h3 id="RPC框架功能更齐全"><a href="#RPC框架功能更齐全" class="headerlink" title="RPC框架功能更齐全"></a>RPC框架功能更齐全</h3><p>成熟的 RPC框架还提供好了“服务自动注册与发现”、”智能负载均衡”、“可视化的服务治理和运维”、“运行期流量调度”等等功能，这些也算是选择 RPC 进行服务注册和发现的一方面原因吧！</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>RPC</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式协调</title>
    <url>/2022/05/24/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83/</url>
    <content><![CDATA[<p>🍋 🍋 🍋 🍋 🍋</p>
<span id="more"></span>

<h1 id="1-ZooKeeper-相关概念总结-入门"><a href="#1-ZooKeeper-相关概念总结-入门" class="headerlink" title="1 ZooKeeper 相关概念总结(入门)"></a>1 ZooKeeper 相关概念总结(入门)</h1><h2 id="1-1-ZooKeeper-介绍"><a href="#1-1-ZooKeeper-介绍" class="headerlink" title="1.1 ZooKeeper 介绍"></a>1.1 ZooKeeper 介绍</h2><h3 id="1-1-1-ZooKeeper-概览"><a href="#1-1-1-ZooKeeper-概览" class="headerlink" title="1.1.1 ZooKeeper 概览"></a>1.1.1 ZooKeeper 概览</h3><p>ZooKeeper 是一个开源的<strong>分布式协调服务，</strong>它的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</p>
<p><strong>ZooKeeper 为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如数据发布&#x2F;订阅、负载均衡、命名服务、分布式协调&#x2F;通知、集群管理、Master 选举、分布式锁和分布式队列等功能。</strong></p>
<p>另外，<strong>ZooKeeper 将数据保存在内存中，性能是非常棒的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景）。</strong></p>
<h3 id="1-1-2-ZooKeeper-特点"><a href="#1-1-2-ZooKeeper-特点" class="headerlink" title="1.1.2 ZooKeeper 特点"></a>1.1.2 ZooKeeper 特点</h3><ul>
<li><strong>顺序一致性：</strong> 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</li>
<li><strong>原子性：</strong> 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</li>
<li><strong>单一系统映像 ：</strong> 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</li>
<li><strong>可靠性：</strong> 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</li>
<li></li>
</ul>
<h3 id="1-1-3-ZooKeeper-典型应用场景"><a href="#1-1-3-ZooKeeper-典型应用场景" class="headerlink" title="1.1.3 ZooKeeper 典型应用场景"></a>1.1.3 ZooKeeper 典型应用场景</h3><ol>
<li><strong>分布式锁</strong> ： 通过创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。</li>
<li><strong>命名服务</strong> ：可以通过 ZooKeeper 的顺序节点生成全局唯一 ID</li>
<li><strong>数据发布&#x2F;订阅</strong> ：通过 <strong>Watcher 机制</strong> 可以很方便地实现数据发布&#x2F;订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。<blockquote>
<p>实际上，这些功能的实现基本都得益于 ZooKeeper 可以保存数据的功能，但是 ZooKeeper 不适合保存大量数据，这一点需要注意。</p>
</blockquote>
</li>
</ol>
<h3 id="1-1-4-有哪些著名的开源项目用到了-ZooKeeper"><a href="#1-1-4-有哪些著名的开源项目用到了-ZooKeeper" class="headerlink" title="1.1.4 有哪些著名的开源项目用到了 ZooKeeper?"></a>1.1.4 有哪些著名的开源项目用到了 ZooKeeper?</h3><ol>
<li><strong>Kafka</strong> : ZooKeeper 主要为 Kafka 提供 Broker 和 Topic 的注册以及多个 Partition 的负载均衡等功能。</li>
<li><strong>Hbase</strong> : ZooKeeper 为 Hbase 提供确保整个集群只有一个 Master 以及保存和提供 regionserver 状态信息（是否在线）等功能。</li>
<li><strong>Hadoop</strong> : ZooKeeper 为 Namenode 提供高可用支持</li>
</ol>
<h2 id="1-2-ZooKeeper-重要概念解读"><a href="#1-2-ZooKeeper-重要概念解读" class="headerlink" title="1.2 ZooKeeper 重要概念解读"></a>1.2 ZooKeeper 重要概念解读</h2><h3 id="1-2-1-Data-model（数据模型）"><a href="#1-2-1-Data-model（数据模型）" class="headerlink" title="1.2.1 Data model（数据模型）"></a>1.2.1 Data model（数据模型）</h3><p>ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，这些数据可以是数字、字符串或者是二级制序列。并且。每个节点还可以拥有 N 个子节点，最上层是根节点以“&#x2F;”来代表。每个数据节点在 ZooKeeper 中被称为 <strong>znode</strong>，它是 ZooKeeper 中数据的最小单元。并且，每个 znode 都一个唯一的路径标识。</p>
<p>强调一句：<strong>ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以不要放比较大的数据在 znode 上，ZooKeeper 给出的上限是每个结点的数据大小最大是 1M。</strong></p>
<h3 id="1-2-2-znode（数据节点）"><a href="#1-2-2-znode（数据节点）" class="headerlink" title="1.2.2 znode（数据节点）"></a>1.2.2 znode（数据节点）</h3><blockquote>
<p>ZooKeeper 中数据的最小单元。你要存放的数据就放在上面，是你使用 ZooKeeper 过程中经常需要接触到的一个概念。</p>
</blockquote>
<h4 id="znode-4-种类型"><a href="#znode-4-种类型" class="headerlink" title="znode 4 种类型"></a>znode 4 种类型</h4><ul>
<li><strong>持久（PERSISTENT）节点</strong> ：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。</li>
<li><strong>临时（EPHEMERAL）节点</strong> ：临时节点的生命周期是与 <strong>客户端会话（session）</strong> 绑定的，<strong>会话消失则节点消失</strong> 。并且，<strong>临时节点只能做叶子节点</strong> ，不能创建子节点。</li>
<li><strong>持久顺序（PERSISTENT_SEQUENTIAL）节点</strong> ：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 &#x2F;node1&#x2F;app0000000001 、&#x2F;node1&#x2F;app0000000002 。</li>
<li><strong>临时顺序（EPHEMERAL_SEQUENTIAL）节点</strong> ：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。</li>
</ul>
<h4 id="znode-数据结构"><a href="#znode-数据结构" class="headerlink" title="znode 数据结构"></a>znode 数据结构</h4><p>每个 znode 由 2 部分组成:</p>
<ul>
<li><strong>stat</strong> ：状态信息</li>
<li><strong>data</strong> ： 节点存放的数据的具体内容</li>
</ul>
<h3 id="1-2-3-版本"><a href="#1-2-3-版本" class="headerlink" title="1.2.3 版本"></a>1.2.3 版本</h3><p>在前面我们已经提到，对应于每个 znode，ZooKeeper 都会为其维护一个叫作 <strong>Stat</strong> 的数据结构，Stat 中记录了这个 znode 的三个相关的版本：</p>
<ul>
<li><strong>dataVersion</strong> ：当前 znode 节点的版本号</li>
<li><strong>cversion</strong> ： 当前 znode 子节点的版本</li>
<li><strong>aclVersion</strong> ： 当前 znode 的 ACL 的版本。</li>
</ul>
<h3 id="1-2-4-ACL（权限控制）"><a href="#1-2-4-ACL（权限控制）" class="headerlink" title="1.2.4 ACL（权限控制）"></a>1.2.4 ACL（权限控制）</h3><p>ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。<br>对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：</p>
<ul>
<li><strong>CREATE</strong> : 能创建子节点</li>
<li><strong>READ</strong> ：能获取节点数据和列出其子节点</li>
<li><strong>WRITE</strong> : 能设置&#x2F;更新节点数据</li>
<li><strong>DELETE</strong> : 能删除子节点</li>
<li><strong>ADMIN</strong> : 能设置节点 ACL 的权限</li>
</ul>
<p>其中尤其需要注意的是，<strong>CREATE</strong> 和 <strong>DELETE</strong> 这两种权限都是针对 <strong>子节点</strong> 的权限控制。</p>
<p>对于身份认证，提供了以下几种方式：</p>
<ul>
<li><strong>world</strong> ： 默认方式，所有用户都可无条件访问。</li>
<li><strong>auth</strong> :不使用任何 id，代表任何已认证的用户。</li>
<li><strong>digest</strong> :用户名:密码认证方式： <em>username:password</em> 。</li>
<li><strong>ip</strong> : 对指定 ip 进行限制。</li>
</ul>
<h3 id="1-2-5-Watcher（事件监听器）"><a href="#1-2-5-Watcher（事件监听器）" class="headerlink" title="1.2.5 Watcher（事件监听器）"></a>1.2.5 Watcher（事件监听器）</h3><p>Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251020705.png" alt="img"></p>
<p><em>破音：非常有用的一个特性，都拿出小本本记好了，后面用到 ZooKeeper 基本离不开 Watcher（事件监听器）机制</em></p>
<h3 id="1-2-6-会话（Session）"><a href="#1-2-6-会话（Session）" class="headerlink" title="1.2.6 会话（Session）"></a>1.2.6 会话（Session）</h3><p>Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 TCP 长连接，通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的 Watcher 事件通知。</p>
<p>Session 有一个属性叫做：sessionTimeout ，sessionTimeout 代表会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。</p>
<p>另外，在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionID。由于 sessionID是 ZooKeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。</p>
<h2 id="1-3-ZooKeeper-集群"><a href="#1-3-ZooKeeper-集群" class="headerlink" title="1.3  ZooKeeper 集群"></a>1.3  ZooKeeper 集群</h2><p>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。ZooKeeper 官方提供的架构图就是一个 ZooKeeper 集群整体对外提供服务。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251020361.png" alt="img"><br>上图中每一个 Server 代表一个安装 ZooKeeper 服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 ZAB 协议（ZooKeeper Atomic Broadcast）来保持数据的一致性。<br><strong>最典型集群模式： Master&#x2F;Slave 模式（主备模式）</strong>。在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</p>
<h3 id="1-3-1-ZooKeeper-集群角色"><a href="#1-3-1-ZooKeeper-集群角色" class="headerlink" title="1.3.1 ZooKeeper 集群角色"></a>1.3.1 ZooKeeper 集群角色</h3><p>但是，在 ZooKeeper 中没有选择传统的 Master&#x2F;Slave 概念，而是引入了 Leader、Follower 和 Observer 三种角色。如下图所示<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251021015.png" alt="img"><br>ZooKeeper 集群中的所有机器通过一个 <strong>Leader 选举过程</strong> 来选定一台称为 “<strong>Leader</strong>” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，<strong>Follower</strong> 和 <strong>Observer</strong> 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。</p>
<table>
<thead>
<tr>
<th>角色</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Leader</td>
<td>为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。</td>
</tr>
<tr>
<td>Follower</td>
<td>为客户端提供读服务，如果是写服务则转发给 Leader。参与选举过程中的投票。</td>
</tr>
<tr>
<td>Observer</td>
<td>为客户端提供读服务，如果是写服务则转发给 Leader。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。此角色于 ZooKeeper3.3 系列新增的角色。</td>
</tr>
</tbody></table>
<p>当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器。<br>这个过程大致是这样的：</p>
<ol>
<li><strong>Leader election（选举阶段）</strong>：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。</li>
<li><strong>Discovery（发现阶段）</strong> ：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。</li>
<li><strong>Synchronization（同步阶段）</strong> :同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。</li>
<li><strong>Broadcast（广播阶段）</strong> :到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</li>
</ol>
<h3 id="1-3-2-ZooKeeper-集群中的服务器状态"><a href="#1-3-2-ZooKeeper-集群中的服务器状态" class="headerlink" title="1.3.2 ZooKeeper 集群中的服务器状态"></a>1.3.2 ZooKeeper 集群中的服务器状态</h3><ul>
<li><strong>LOOKING</strong> ：寻找 Leader。</li>
<li><strong>LEADING</strong> ：Leader 状态，对应的节点为 Leader。</li>
<li><strong>FOLLOWING</strong> ：Follower 状态，对应的节点为 Follower。</li>
<li><strong>OBSERVING</strong> ：Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。<h3 id="1-3-3-ZooKeeper-选举的过半机制防止脑裂"><a href="#1-3-3-ZooKeeper-选举的过半机制防止脑裂" class="headerlink" title="1.3.3 ZooKeeper 选举的过半机制防止脑裂"></a>1.3.3 ZooKeeper 选举的过半机制防止脑裂</h3></li>
</ul>
<p><strong>何为集群脑裂？</strong><br>对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候子集群各自选主导致“脑裂”的情况。<br><strong>过半机制是如何防止脑裂现象产生的？</strong><br>ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。</p>
<h2 id="1-4-ZAB-协议和-Paxos-算法"><a href="#1-4-ZAB-协议和-Paxos-算法" class="headerlink" title="1.4 ZAB 协议和 Paxos 算法"></a>1.4 ZAB 协议和 Paxos 算法</h2><p>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos 算法 ，而是使用 Paxos算法的ZAB 协议作为其保证数据一致性的核心算法。另外，在 ZooKeeper 的官方文档中也指出，ZAB 协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为 Zookeeper 设计的崩溃可恢复的原子消息广播算法。</p>
<h3 id="1-4-1-ZAB-协议介绍"><a href="#1-4-1-ZAB-协议介绍" class="headerlink" title="1.4.1 ZAB 协议介绍"></a>1.4.1 ZAB 协议介绍</h3><p>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为<strong>分布式协调服务 ZooKeeper</strong> 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的<strong>数据一致性</strong>。</p>
<h3 id="1-4-2-ZAB-协议两种基本的模式：崩溃恢复和消息广播"><a href="#1-4-2-ZAB-协议两种基本的模式：崩溃恢复和消息广播" class="headerlink" title="1.4.2 ZAB 协议两种基本的模式：崩溃恢复和消息广播"></a>1.4.2 ZAB 协议两种基本的模式：崩溃恢复和消息广播</h3><ul>
<li><strong>崩溃恢复</strong> ：当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。其中，<strong>所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致</strong>。</li>
<li><strong>消息广播</strong> ：<strong>当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。</strong> 当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。<h2 id="1-5-总结"><a href="#1-5-总结" class="headerlink" title="1.5 总结"></a>1.5 总结</h2></li>
</ul>
<ol>
<li>ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。</li>
<li>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。</li>
<li>ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持 znode 中存储的数据量较小的进一步原因）。</li>
<li>ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地明显，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</li>
<li>ZooKeeper 有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个 znode 被创建了，除非主动进行 znode 的移除操作，否则这个 znode 将一直保存在 ZooKeeper 上。</li>
<li>ZooKeeper 底层其实只提供了两个功能：① 管理（存储、读取）用户程序提交的数据；② 为用户程序提供数据节点监听服务。</li>
</ol>
<h1 id="2-ZooKeeper-相关概念总结-进阶"><a href="#2-ZooKeeper-相关概念总结-进阶" class="headerlink" title="2 ZooKeeper 相关概念总结(进阶)"></a>2 ZooKeeper 相关概念总结(进阶)</h1><h2 id="2-1-一致性问题"><a href="#2-1-一致性问题" class="headerlink" title="2.1 一致性问题"></a>2.1 一致性问题</h2><p>设计一个分布式系统必定会遇到一个问题—— <strong>因为分区容忍性（partition tolerance）的存在，就必定要求我们需要在系统可用性（availability）和数据一致性（consistency）中做出权衡</strong> 。这就是著名的 CAP 定理。</p>
<h2 id="2-2-一致性协议和算法"><a href="#2-2-一致性协议和算法" class="headerlink" title="2.2 一致性协议和算法"></a>2.2 一致性协议和算法</h2><p>而为了解决数据一致性问题，在科学家和程序员的不断探索中，就出现了很多的一致性协议和算法。比如 2PC（两阶段提交），3PC（三阶段提交），Paxos算法等等。</p>
<blockquote>
<p>请你思考一个问题，同学之间如果采用传纸条的方式去传播消息，那么就会出现一个问题——我咋知道我的小纸条有没有传到我想要传递的那个人手中呢？万一被哪个小家伙给劫持篡改了呢，对吧？</p>
</blockquote>
<p>这个时候就引申出一个概念—— <strong>拜占庭将军问题</strong> 。它意指 <strong>在不可靠信道上试图通过消息传递的方式达到一致性是不可能的</strong>， 所以所有的一致性算法的 <strong>必要前提</strong> 就是安全可靠的消息通道。</p>
<p>而为什么要去解决数据一致性的问题？你想想，如果一个秒杀系统将服务拆分成了下订单和加积分服务，这两个服务部署在不同的机器上了，万一在消息的传播过程中积分系统宕机了，总不能你这边下了订单却没加积分吧？你总得保证两边的数据需要一致吧？</p>
<h3 id="2-2-1-2PC（两阶段提交）"><a href="#2-2-1-2PC（两阶段提交）" class="headerlink" title="2.2.1 2PC（两阶段提交）"></a>2.2.1 2PC（两阶段提交）</h3><p>两阶段提交是一种保证分布式系统数据一致性的协议，现在很多数据库都是采用的两阶段提交协议来完成 <strong>分布式事务</strong> 的处理。</p>
<blockquote>
<p>以秒杀系统的下单和加积分两个系统来举例，我们此时下完订单会发个消息给积分系统告诉它下面该增加积分了。如果我们仅仅是发送一个消息也不收回复，那么我们的订单系统怎么能知道积分系统的收到消息的情况呢？如果我们增加一个收回复的过程，那么当积分系统收到消息后返回给订单系统一个 Response ，但在中间出现了网络波动，那个回复消息没有发送成功，订单系统是不是以为积分系统消息接收失败了？它是不是会回滚事务？但此时积分系统是成功收到消息的，它就会去处理消息然后给用户增加积分，这个时候就会出现积分加了但是订单没下成功。</p>
</blockquote>
<p>所以我们所需要解决的是在分布式系统中，整个调用链中，我们所有服务的数据处理要么都成功要么都失败，即所有服务的 <strong>原子性问题</strong> 。</p>
<p>在两阶段提交中，主要涉及到两个角色，分别是协调者和参与者。<br>第一阶段：事务发起者向协调者发起事务请求，协调者向参与者发送请求，参与者执行事务但不提交，并将undo和Redo信息记入事务日志中，向协调者返回是否准备好了；<br>第二阶段：协调者根据参与者反馈决定是进行事务的提交操作，即提交事务或者回滚事务；<br>如果第一阶段不是所有参与者都返回了消息，协调者将会给所有参与者发送 <strong>回滚事务的 rollback 请求</strong>，参与者收到之后将会 <strong>回滚它在第一阶段所做的事务处理</strong> ，然后再将处理情况返回给协调者，最终协调者收到响应后便给事务发起者返回处理失败的结果。<br>2PC 实现得还是比较鸡肋的，因为事实上它只解决了各个事务的原子性问题，随之也带来了很多的问题。</p>
<ul>
<li><strong>单点故障问题</strong>，如果协调者挂了那么整个系统都处于不可用的状态了。</li>
<li><strong>阻塞问题</strong>，即当协调者发送 prepare 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能。</li>
<li><strong>数据不一致问题</strong>，比如当第二阶段，协调者只发送了一部分的 commit 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题。</li>
</ul>
<h3 id="2-2-2-3PC（三阶段提交）"><a href="#2-2-2-3PC（三阶段提交）" class="headerlink" title="2.2.2 3PC（三阶段提交）"></a>2.2.2 3PC（三阶段提交）</h3><p>因为2PC存在的一系列问题，比如单点，容错机制缺陷等等，从而产生了 <strong>3PC（三阶段提交）</strong> 。那么这三阶段又分别是什么呢？</p>
<ol>
<li><strong>CanCommit阶段</strong>：协调者向所有参与者发送 CanCommit 请求，参与者收到请求后会根据自身情况查看是否能执行事务，如果可以则返回 YES 响应并进入预备状态，否则返回 NO 。</li>
<li><strong>PreCommit阶段</strong>：协调者根据参与者返回的响应来决定是否可以进行下面的 PreCommit 操作。如果上面参与者返回的都是 YES，那么协调者将向所有参与者发送 PreCommit 预提交请求，<strong>参与者收到预提交请求后，会进行事务的执行操作，并将 Undo 和 Redo 信息写入事务日志中</strong> ，最后如果参与者顺利执行了事务则给协调者返回成功的响应。如果在第一阶段协调者收到了 <strong>任何一个 NO</strong> 的信息，或者 <strong>在一定时间内</strong> 并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求（abort），参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务。</li>
<li><strong>DoCommit阶段</strong>：这个阶段其实和 2PC 的第二阶段差不多，如果协调者收到了所有参与者在 PreCommit 阶段的 YES 响应，那么协调者将会给所有参与者发送 DoCommit 请求，<strong>参与者收到 DoCommit 请求后则会进行事务的提交工作</strong>，完成后则会给协调者返回响应，协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 PreCommit 阶段 <strong>收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应</strong> ，那么就会进行中断请求的发送，参与者收到中断请求后则会 <strong>通过上面记录的回滚日志</strong> 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251021839.png" alt="img"><br>3PC多处采用超时中断，减少同步阻塞的时间<br>总之，3PC 通过一系列的超时机制很好的缓解了<strong>阻塞问题</strong>，但是<strong>最重要的一致性并没有得到根本的解决</strong>，比如在 PreCommit 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。</p>
<p>所以，要解决一致性问题还需要靠 Paxos 算法⭐️ ⭐️ ⭐️ 。</p>
<h3 id="2-2-3-Paxos-算法"><a href="#2-2-3-Paxos-算法" class="headerlink" title="2.2.3 Paxos 算法"></a>2.2.3 Paxos 算法</h3><p>Paxos 算法是基于<strong>消息传递且具有高度容错特性的一致性算法</strong>，是目前公认的解决分布式一致性问题最有效的算法之一，<strong>其解决的问题就是在分布式系统中如何就某个值（决议）达成一致</strong> 。<br>三个角色：Proposer提案者、Acceptor表决者、Learner学习者<br>两个阶段：Prepare 和 accept 阶段</p>
<h4 id="prepare-阶段"><a href="#prepare-阶段" class="headerlink" title="prepare 阶段"></a>prepare 阶段</h4><p>提案者负责提出proposal，每个提案者在提案时都会获得一个全局唯一的递增的提案编号，然后将该编号赋予要提出的提案；<br>表决者收到提案编号后，如果提案编号大于本地最大已accept的提案编号，在批准提案时，会将以前接收过的最大编号的提案作为响应反馈给proposer；</p>
<h4 id="accept-阶段"><a href="#accept-阶段" class="headerlink" title="accept 阶段"></a>accept 阶段</h4><p>当一个提案者收到超过一半的Acceptor的批准，提案者会给所有Accept发送真正的提案内容和提案编号（第一阶段就是试探）；<br>表决者收到提案会对比提案者发送过来的提案编号是否大于等于本地最大以及批准的最大提案编号，如果是，那就accept该提案（执行内容但不提交），随后将情况返回给proposer，否则不回应或者返回NO；<br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 <strong>递增</strong> 该 Proposal 的编号，然后 <strong>重新进入 Prepare 阶段</strong> 。</p>
<h4 id="paxos-算法的死循环问题"><a href="#paxos-算法的死循环问题" class="headerlink" title="paxos 算法的死循环问题"></a>paxos 算法的死循环问题</h4><p>两个提案者先后分别发送了两个不同的提案，先者不能在第二阶段被批准了，因为后者发送了一个编号更大的提案；<br><strong>就允许一个能提案</strong> 就行了。</p>
<h2 id="2-3-引出-ZAB"><a href="#2-3-引出-ZAB" class="headerlink" title="2.3 引出 ZAB"></a>2.3 引出 ZAB</h2><h3 id="2-3-1-Zookeeper架构"><a href="#2-3-1-Zookeeper架构" class="headerlink" title="2.3.1 Zookeeper架构"></a>2.3.1 Zookeeper架构</h3><p>作为一个优秀高效且可靠的分布式协调框架，ZooKeeper 在解决分布式数据一致性问题时并没有直接使用 Paxos ，而是专门定制了一致性协议叫做 ZAB(ZooKeeper Atomic Broadcast) 原子广播协议，该协议能够很好地支持 <strong>崩溃恢复</strong> 。</p>
<h3 id="2-3-2-ZAB-中的三个角色"><a href="#2-3-2-ZAB-中的三个角色" class="headerlink" title="2.3.2 ZAB 中的三个角色"></a>2.3.2 ZAB 中的三个角色</h3><ul>
<li>Leader ：集群中 <strong>唯一的写请求处理者</strong> ，能够发起投票（投票也是为了进行写请求）。</li>
<li>Follower：能够接收客户端的请求，如果是读请求则可以自己处理，<strong>如果是写请求则要转发给 Leader</strong> 。在选举过程中会参与投票，<strong>有选举权和被选举权</strong> 。</li>
<li>Observer ：就是没有选举权和被选举权的 Follower 。</li>
</ul>
<p>在 ZAB 协议中对 zkServer(即上面我们说的三个角色的总称) 还有两种模式的定义，分别是 <strong>消息广播</strong> 和 <strong>崩溃恢复</strong> 。</p>
<h3 id="2-3-3-消息广播模式"><a href="#2-3-3-消息广播模式" class="headerlink" title="2.3.3 消息广播模式"></a>2.3.3 消息广播模式</h3><p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251021691.png" alt="img"><br>顺序一致性<br>在 Leader 这端，它为每个其他的 zkServer 准备了一个 <strong>队列</strong> ，采用先进先出的方式发送消息。由于协议是 <strong>通过 TCP <strong>来进行网络通信的，保证了消息的发送顺序性，接受顺序性也得到了保证。<br>同时在ZAB中还定义了一个</strong>全局单调递增的事务ID ZXID</strong>来保证顺序性</p>
<h3 id="2-3-4-崩溃恢复模式"><a href="#2-3-4-崩溃恢复模式" class="headerlink" title="2.3.4 崩溃恢复模式"></a>2.3.4 崩溃恢复模式</h3><p>说到崩溃恢复我们首先要提到 ZAB 中的 Leader 选举算法，当系统出现崩溃影响最大应该是 Leader 的崩溃，因为我们只有一个 Leader ，所以当 Leader 出现问题的时候我们势必需要重新选举 Leader 。</p>
<p>Leader 选举可以分为两个不同的阶段,</p>
<ul>
<li>ZAB初始化选举：初始时，整个集群处于looking状态；每个服务器都会先给自己投一票，投票内容为服务器的myid和ZXID，初始化全为0；先比较ZXID，ZXID大的优先为Leader，如果相同则比较myid，myid大的优先作为Leader；整个服务器从Looking变为了正常状态。</li>
<li>三台服务器挂了一个(Leader挂了)：剩余两台由following变为looking状态；zxid 大的优先做Leading，如果相同那么就 myid 大的优先；</li>
</ul>
<p><strong>崩溃恢复</strong>含义就是<strong>：当集群中有机器挂了，我们整个集群如何保证数据一致性？</strong><br>如果只是Follower挂了，只要没超过半数，在Leader中会维护队列，不用担心后面的数据没接收到导致数据不一致性；<br>如果Leader挂了，先暂停服务变为 Looking 状态然后进行 Leader 的重新选举，但这个就要分为两种情况了，分别是</p>
<ul>
<li><strong>确保已经被Leader提交的提案最终能够被所有的Follower提交</strong></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251021292.png" alt="img"></p>
<ul>
<li><strong>跳过那些已经被丢弃的提案</strong></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251021292.png"></p>
<h2 id="2-4-Zookeeper的几个理论知识"><a href="#2-4-Zookeeper的几个理论知识" class="headerlink" title="2.4 Zookeeper的几个理论知识"></a>2.4 Zookeeper的几个理论知识</h2><p>数据模型、回话、ACL、Watcher机制（见1.2 Zookeeper重要概念解读）</p>
<h2 id="2-5-Zookeeper的几个典型应用场景"><a href="#2-5-Zookeeper的几个典型应用场景" class="headerlink" title="2.5 Zookeeper的几个典型应用场景"></a>2.5 Zookeeper的几个典型应用场景</h2><h3 id="2-5-1-选主"><a href="#2-5-1-选主" class="headerlink" title="2.5.1 选主"></a>2.5.1 选主</h3><p><strong>临时节点</strong>：因为 Zookeeper 的强一致性，能够很好地在保证 <strong>在高并发的情况下保证节点创建的全局唯一性</strong> (即无法重复创建同样的节点)。</p>
<p>利用这个特性，我们可以 <strong>让多个客户端创建一个指定的节点</strong> ，创建成功的就是 master。</p>
<p>master挂了怎么办？（<strong>利用临时节点状态和watcher</strong>）<br>我们是不是可以 <strong>让其他不是 master 的节点监听节点的状态</strong> ，比如说我们监听这个临时节点的父节点，如果子节点个数变了就代表 master 挂了，这个时候我们 <strong>触发回调函数进行重新选举</strong> ，或者我们直接监听节点的状态，我们可以通过节点是否已经失去连接来判断 master 是否挂了等等。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251023434.png" alt="img"></p>
<h3 id="2-5-2-分布式锁"><a href="#2-5-2-分布式锁" class="headerlink" title="2.5.2 分布式锁"></a>2.5.2 分布式锁</h3><p> <strong>zk在高并发的情况下保证节点创建的全局唯一性</strong><br>利用临时节点的创建来实现<br>让多个客户端同时创建一个临时节点，<strong>创建成功的就说明获取到了锁</strong>。然后没有获取到锁的客户端也像上面选主的非主节点创建一个 watcher 进行节点状态的监听，如果这个互斥锁被释放了（可能获取锁的客户端宕机了，或者那个客户端主动释放了锁）可以调用回调函数重新获得锁。</p>
<h4 id="使用-zookeeper-同时实现-共享锁和独占锁-（数据模型中的临时顺序节点）"><a href="#使用-zookeeper-同时实现-共享锁和独占锁-（数据模型中的临时顺序节点）" class="headerlink" title="使用 zookeeper 同时实现 共享锁和独占锁 （数据模型中的临时顺序节点）"></a>使用 zookeeper 同时实现 共享锁和独占锁 （数据模型中的临时顺序节点）</h4><p>规定所有创建节点必须有序，当你是读请求（要获取共享锁）的话，如果 <strong>没有比自己更小的节点，或比自己小的节点都是读请求</strong> ，则可以获取到读锁，然后就可以开始读了。<strong>若比自己小的节点中有写请求</strong> ，则当前客户端无法获取到读锁，只能等待前面的写请求完成。<br>如果你是写请求（获取独占锁），若 <strong>没有比自己更小的节点</strong> ，则表示当前客户端可以直接获取到写锁，对数据进行修改。若发现 <strong>有比自己更小的节点，无论是读操作还是写操作，当前客户端都无法获取到写锁</strong> ，等待所有前面的操作完成。</p>
<p>优化（比如当一个锁得到释放它会通知所有等待的客户端从而造成 <strong>羊群效应</strong>）<br><strong>读请求监听比自己小的最后一个写请求节点</strong><br><strong>写请求只监听比自己小的最后一个节点</strong></p>
<h3 id="2-5-3-命名服务"><a href="#2-5-3-命名服务" class="headerlink" title="2.5.3 命名服务"></a>2.5.3 命名服务</h3><p>zookeeper 是通过 <strong>树形结构</strong> 来存储数据节点的，那也就是说，对于每个节点的 <strong>全路径</strong>，它必定是唯一的，我们可以使用节点的全路径作为命名方式了。而且更重要的是，路径是我们可以自己定义的，这对于我们对有些有语意的对象的ID设置可以更加便于理解。</p>
<h3 id="2-5-4-集群管理和注册中心"><a href="#2-5-4-集群管理和注册中心" class="headerlink" title="2.5.4 集群管理和注册中心"></a>2.5.4 集群管理和注册中心</h3><p>集群管理：<br>zookeeper 天然支持的 watcher 和 临时节点能很好的实现这些需求。我们可以为每条机器创建临时节点，并监控其父节点，如果子节点列表有变动（我们可能创建删除了临时节点），那么我们可以使用在其父节点绑定的 watcher 进行状态监控和回调。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251023906.png" alt="img"></p>
<p>注册中心：<br><strong>服务提供者</strong> 在 zookeeper 中创建一个临时节点并且将自己的 ip、port、调用方式 写入节点，当 <strong>服务消费者</strong> 需要进行调用的时候会 <strong>通过注册中心找到相应的服务的地址列表(IP端口什么的)</strong> ，并缓存到本地(方便以后调用)，当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从地址列表中取一个服务提供者的服务器调用服务。<br>当服务提供者的某台服务器宕机或下线时，相应的地址会从服务提供者地址列表中移除。同时，注册中心会将新的服务地址列表发送给服务消费者的机器并缓存在消费者本机（当然你可以让消费者进行节点监听，我记得 Eureka 会先试错，然后再更新）。<br><img src="https://cdn.jsdelivr.net/gh/MapleFv/BolgImgs/202205251023326.png" alt="img"></p>
<h2 id="2-6-总结"><a href="#2-6-总结" class="headerlink" title="2.6 总结"></a>2.6 总结</h2><ul>
<li>分布式与集群的区别</li>
<li>2PC 、3PC 以及 paxos 算法这些一致性框架的原理和实现。</li>
<li>zookeeper 专门的一致性算法 ZAB 原子广播协议的内容（Leader 选举、崩溃恢复、消息广播）。</li>
<li>zookeeper 中的一些基本概念，比如 ACL，数据节点，会话，watcher机制等等。</li>
<li>zookeeper 的典型应用场景，比如选主，注册中心等等。</li>
</ul>
<p>参考：<a href="https://javaguide.cn/">https://javaguide.cn/</a></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
</search>
